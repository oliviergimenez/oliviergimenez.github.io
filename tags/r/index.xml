<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>R | Olivier Gimenez</title><link>https://oliviergimenez.github.io/tags/r/</link><atom:link href="https://oliviergimenez.github.io/tags/r/index.xml" rel="self" type="application/rss+xml"/><description>R</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© Olivier Gimenez 2021</copyright><lastBuildDate>Fri, 18 Dec 2020 00:00:00 +0000</lastBuildDate><image><url>https://oliviergimenez.github.io/img/flyfishing.jpg</url><title>R</title><link>https://oliviergimenez.github.io/tags/r/</link></image><item><title>Workshop on reproducible science</title><link>https://oliviergimenez.github.io/blog/reproscience2020/</link><pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/reproscience2020/</guid><description>&lt;p>Workshop to come on reproducible science in our lab.&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">🧑‍🔬💻♻️ Planning a 1-day workshop on reproducible science for our lab &lt;a href="https://twitter.com/cefemontpellier?ref_src=twsrc%5Etfw">@cefemontpellier&lt;/a>. We&amp;#39;ll use R and RStudio, Git, GitHub, R Markdown, tidyverse and sf 🤩&lt;br>&lt;br>Material here &lt;a href="https://t.co/QApKQsl1FU">https://t.co/QApKQsl1FU&lt;/a> &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> &lt;a href="https://twitter.com/hashtag/ReproducibleScience?src=hash&amp;amp;ref_src=twsrc%5Etfw">#ReproducibleScience&lt;/a> &lt;a href="https://twitter.com/twitthair1?ref_src=twsrc%5Etfw">@twitthair1&lt;/a> &lt;br>&lt;br>pix by &lt;a href="https://twitter.com/scriberian?ref_src=twsrc%5Etfw">@scriberian&lt;/a> &lt;a href="https://t.co/LFBwZmelit">pic.twitter.com/LFBwZmelit&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez 🖖 (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1339896916109373440?ref_src=twsrc%5Etfw">December 18, 2020&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Some random piece of code</title><link>https://oliviergimenez.github.io/blog/pieceofcode/</link><pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/pieceofcode/</guid><description>&lt;p>Gathered some code on occupancy, capture-recapture &amp;amp; epidemiological models, social networks, spatial stuff, textual analyses, reproducible science, etc&amp;hellip;&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">👩‍💻👨‍💻 In hope it&amp;#39;s useful, I gathered random pieces of code I wrote on occupancy, capture-recapture &amp;amp; epidemiological models, social networks, spatial stuff, textual analyses, &lt;a href="https://twitter.com/hashtag/DeepLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw">#DeepLearning&lt;/a> and the &lt;a href="https://twitter.com/hashtag/tidyverse?src=hash&amp;amp;ref_src=twsrc%5Etfw">#tidyverse&lt;/a> ➡️ &lt;a href="https://t.co/T1PlbmDLZO">https://t.co/T1PlbmDLZO&lt;/a> I also went full purple &lt;a href="https://twitter.com/MoonbeamLevels?ref_src=twsrc%5Etfw">@MoonbeamLevels&lt;/a> 💜 &lt;a href="https://t.co/q6vK4LYVS7">pic.twitter.com/q6vK4LYVS7&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez 🖖 (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1291749139596955650?ref_src=twsrc%5Etfw">August 7, 2020&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Statistical ecology</title><link>https://oliviergimenez.github.io/my-project/external-project/methods/</link><pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/my-project/external-project/methods/</guid><description>&lt;p>Trained in mathematics and statistics in particular, I have developed a bottomless taste for questions in
&lt;a href="http://rsbl.royalsocietypublishing.org/content/10/12/20140698" target="_blank" rel="noopener">statistical ecology&lt;/a>.&lt;/p>
&lt;p>I often resort to
&lt;a href="https://oliviergimenez.github.io/publication/books/" target="_blank" rel="noopener">state-space models&lt;/a>, and hidden Markov models (e.g.,
&lt;a href="https://oliviergimenez.github.io/pubs/Gimenezetal2014.pdf">here&lt;/a> and
&lt;a href="https://oliviergimenez.github.io/pubs/Gimenezetal2012TPB.pdf">here&lt;/a>) in particular, to develop statistical methods for capture-recapture, occupancy and integrated population models.&lt;/p>
&lt;p>In our group, we address questions in conservation biology to assess species viability, in ecology to study the effect of climate change on animal demography, in evolution to examine life-history tactics and individual heterogeneity and in wildlife management to develop strategies for conservation and conflict mitigation. To account for the human dimension inherent to these questions, I went back to the university to study sociology. A nice illustration of this interdisciplinary work is
&lt;a href="https://tel.archives-ouvertes.fr/tel-01834575/document" target="_blank" rel="noopener">Gilles Maurer&amp;rsquo;s PhD&lt;/a> combining anthropology, demography, economics and genetics to better understand the interactions between captive and wild population of Asian elephants.&lt;/p>
&lt;p>I&amp;rsquo;m doing my best to teach statistics (including the Bayesian way) to the students of the
&lt;a href="https://www.masters-biologie-ecologie.com/blog/" target="_blank" rel="noopener">Ecology and Evolution Master in Montpellier&lt;/a>. We also make efforts to structure the community in France through our
&lt;a href="https://sites.google.com/site/gdrecostat/" target="_blank" rel="noopener">national research group in statistical ecology&lt;/a>. Last but not least, every now and then, our group runs
&lt;a href="https://oliviergimenez.github.io/talks/workshop/" target="_blank" rel="noopener">workshops&lt;/a> to diffuse quantitative methods in the ecological community.&lt;/p></description></item><item><title>Interactive visualisation of bias in occupancy models</title><link>https://oliviergimenez.github.io/blog/interactiveocc/</link><pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/interactiveocc/</guid><description>&lt;p>Interactive data visualisation of bias in occupancy models w/ flexdashboard.&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">Interactive &lt;a href="https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw">#dataviz&lt;/a> of bias in occupancy models w/ &lt;a href="https://twitter.com/hashtag/flexdashboard?src=hash&amp;amp;ref_src=twsrc%5Etfw">#flexdashboard&lt;/a> (aka &lt;a href="https://twitter.com/hashtag/shinyapps?src=hash&amp;amp;ref_src=twsrc%5Etfw">#shinyapps&lt;/a> for the rest of us) &lt;a href="https://t.co/fkYiHfAaEU">https://t.co/fkYiHfAaEU&lt;/a> &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> &lt;a href="https://twitter.com/rstudio?ref_src=twsrc%5Etfw">@rstudio&lt;/a> &lt;a href="https://twitter.com/hashtag/unmarked?src=hash&amp;amp;ref_src=twsrc%5Etfw">#unmarked&lt;/a> &lt;a href="https://t.co/KKGTPE8eJh">https://t.co/KKGTPE8eJh&lt;/a> &lt;a href="https://t.co/Rstpdv8CqJ">pic.twitter.com/Rstpdv8CqJ&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez 🖖 (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1254806087108354048?ref_src=twsrc%5Etfw">April 27,020&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Introduction to spatial analyses in R</title><link>https://oliviergimenez.github.io/blog/intro_spatial/</link><pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/intro_spatial/</guid><description>&lt;blockquote class="twitter-tweet" data-lang="fr">&lt;p lang="en" dir="ltr">👩
💻🗺️👨
💻 The slides of my introduction to &lt;a href="https://twitter.com/hashtag/GIS?src=hash&amp;amp;ref_src=twsrc%5Etfw">#GIS&lt;/a> and &lt;a href="https://twitter.com/hashtag/mapping?src=hash&amp;amp;ref_src=twsrc%5Etfw">#mapping&lt;/a> in &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> using the &lt;a href="https://twitter.com/hashtag/sf?src=hash&amp;amp;ref_src=twsrc%5Etfw">#sf&lt;/a> 📦 and brown 🐻 distribution in the &lt;a href="https://twitter.com/hashtag/pyrenees?src=hash&amp;amp;ref_src=twsrc%5Etfw">#pyrenees&lt;/a> as a case study &lt;a href="https://t.co/SKQOCzbxHn">https://t.co/SKQOCzbxHn&lt;/a> - raw material on &lt;a href="https://twitter.com/hashtag/github?src=hash&amp;amp;ref_src=twsrc%5Etfw">#github&lt;/a> &lt;a href="https://t.co/dHoMz6I2Kp">https://t.co/dHoMz6I2Kp&lt;/a> &lt;a href="https://twitter.com/hashtag/rspatial?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rspatial&lt;/a> &lt;a href="https://twitter.com/hashtag/spatial?src=hash&amp;amp;ref_src=twsrc%5Etfw">#spatial&lt;/a> &lt;a href="https://twitter.com/hashtag/ggplot2?src=hash&amp;amp;ref_src=twsrc%5Etfw">#ggplot2&lt;/a> &lt;a href="https://twitter.com/hashtag/tidyverse?src=hash&amp;amp;ref_src=twsrc%5Etfw">#tidyverse&lt;/a> &lt;a href="https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw">#dataviz&lt;/a> &lt;a href="https://t.co/22eD1Y55d3">pic.twitter.com/22eD1Y55d3&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez 🖖 (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1093882504560414721?ref_src=twsrc%5Etfw">8 février 2019&lt;/a>&lt;/blockquote>
&lt;script asyncc="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Procrastination...</title><link>https://oliviergimenez.github.io/blog/procrastination/</link><pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/procrastination/</guid><description>&lt;blockquote class="twitter-tweet" data-lang="fr">&lt;p lang="en" dir="ltr">Procrastination at its highest level 😜 My first attempt to design hex stickers for our &lt;a href="https://twitter.com/hashtag/R2ucare?src=hash&amp;amp;ref_src=twsrc%5Etfw">#R2ucare&lt;/a> 📦 &lt;a href="https://t.co/ZbclwJKB5W">https://t.co/ZbclwJKB5W&lt;/a> &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> code on &lt;a href="https://twitter.com/hashtag/github?src=hash&amp;amp;ref_src=twsrc%5Etfw">#github&lt;/a> &lt;a href="https://t.co/TbEgjQf7iC">https://t.co/TbEgjQf7iC&lt;/a> Comments more than welcome 😁 &lt;a href="https://t.co/vVdVnJ9B79">pic.twitter.com/vVdVnJ9B79&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez 🖖 (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1093076050656063488?ref_src=twsrc%5Etfw">6 février 2019&lt;/a>&lt;/blockquote>
&lt;sync src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Introduction to the Tidyverse</title><link>https://oliviergimenez.github.io/blog/intro_tidyverse/</link><pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/intro_tidyverse/</guid><description>&lt;blockquote class="twitter-tweet" data-lang="fr">&lt;p lang="en" dir="ltr">My introduction to the &lt;a href="https://twitter.com/hashtag/tidyverse?src=hash&amp;amp;ref_src=twsrc%5Etfw">#tidyverse&lt;/a> for our lab meeting to manipulate and visualise data in &lt;a href="https://twitter.com/hashtag/rstat?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstat&lt;/a> &lt;a href="https://t.co/As9bkXY9GZ">https://t.co/As9bkXY9GZ&lt;/a>. Feel free to steal and modify this material for your own use. Be advised, this is work in progress &amp;amp; a mix of 🇬🇧/🇫🇷😋 Comments welcome! &lt;a href="https://twitter.com/hashtag/datascience?src=hash&amp;amp;ref_src=twsrc%5Etfw">#datascience&lt;/a> &lt;a href="https://twitter.com/hashtag/davaviz?src=hash&amp;amp;ref_src=twsrc%5Etfw">#davaviz&lt;/a> &lt;a href="https://t.co/2vrrdbzuWh">pic.twitter.com/2vrrdbzuWh&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez 🖖 (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1085492126404751360?ref_src=twsrc%5Etfw">16 janvier 2019&lt;/a>&lt;/blockote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>New paper!</title><link>https://oliviergimenez.github.io/blog/articlenina/</link><pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/articlenina/</guid><description>&lt;blockquote class="twitter-tweet" data-lang="fr">&lt;p lang="en" dir="ltr">🐬🇬🇷🇮🇹🇫🇷 New paper by &lt;a href="https://twitter.com/NSantostasi?ref_src=twsrc%5Etfw">@NSantostasi&lt;/a> &lt;a href="https://twitter.com/INEE_CNRS?ref_src=twsrc%5Etfw">@INEE_CNRS&lt;/a> &lt;a href="https://twitter.com/CNRS_OccitaniE?ref_src=twsrc%5Etfw">@CNRS_OccitaniE&lt;/a> &lt;a href="https://twitter.com/IsiteMUSE?ref_src=twsrc%5Etfw">@IsiteMUSE&lt;/a> &lt;a href="https://twitter.com/umontpellier?ref_src=twsrc%5Etfw">@umontpellier&lt;/a> 🤩👏 &lt;a href="https://t.co/6vQ6d9HevV">https://t.co/6vQ6d9HevV&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez 💤 (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1060966359348269058?ref_src=twsrc%5Etfw">9 novembre 2018&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Workshop on spatio-temporal models with INLA</title><link>https://oliviergimenez.github.io/blog/inla_workshop/</link><pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/inla_workshop/</guid><description>&lt;blockquote class="twitter-tweet" data-lang="fr">&lt;p lang="en" dir="ltr">&lt;a href="https://twitter.com/hashtag/INLA?src=hash&amp;amp;ref_src=twsrc%5Etfw">#INLA&lt;/a> workshop on spatio-temporal models in the beautiful city of &lt;a href="https://twitter.com/hashtag/Avignon?src=hash&amp;amp;ref_src=twsrc%5Etfw">#Avignon&lt;/a> 🤩 &lt;a href="https://twitter.com/hashtag/RESSTE?src=hash&amp;amp;ref_src=twsrc%5Etfw">#RESSTE&lt;/a> &lt;a href="https://twitter.com/hashtag/GdREcoStat?src=hash&amp;amp;ref_src=twsrc%5Etfw">#GdREcoStat&lt;/a> &lt;a href="https://twitter.com/oksanagrente?ref_src=twsrc%5Etfw">@oksanagrente&lt;/a> &lt;a href="https://twitter.com/CREEM_cake?ref_src=twsrc%5Etfw">@CREEM_cake&lt;/a> &lt;a href="https://t.co/nuLhIkMiwO">pic.twitter.com/nuLhIkMiwO&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez 💤 (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1060085610793394177?ref_src=twsrc%5Etfw">718&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Crash course on individual-based models using NetLogoR</title><link>https://oliviergimenez.github.io/blog/crashcourse_netlogor/</link><pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/crashcourse_netlogor/</guid><description>&lt;blockquote class="twitter-tweet" data-lang="fr">&lt;p lang="en" dir="ltr">The famous &lt;a href="https://twitter.com/hashtag/NetLogo?src=hash&amp;amp;ref_src=twsrc%5Etfw">#NetLogo&lt;/a> butterfly example coded in &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> w/ &lt;a href="https://twitter.com/hashtag/NetLogoR?src=hash&amp;amp;ref_src=twsrc%5Etfw">#NetLogoR&lt;/a> &lt;a href="https://t.co/VbUUa5vIep">pic.twitter.com/VbUUa5vIep&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez 🚸 (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1059445943689510913?ref_src=twsrc%5Etfw">5 novembre 2018&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;blockquote class="twitter-tweet" data-lang="fr">&lt;p lang="en" dir="ltr">Wolf model from Marucco &amp;amp; &lt;a href="https://twitter.com/eliotmcintire?ref_src=twsrc%5Etfw">@eliotmcintire&lt;/a> coded in &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> w/ &lt;a href="https://twitter.com/hashtag/NetLogoR?src=hash&amp;amp;ref_src=twsrc%5Etfw">#NetLogoR&lt;/a> &amp;amp; &lt;a href="https://twitter.com/hashtag/SpaDES?src=hash&amp;amp;ref_src=twsrc%5Etfw">#SpaDES&lt;/a> &lt;a href="https://t.co/ERx71CIgZv">https://t.co/ERx71CIgZv&lt;/a> &lt;a href="https://t.co/f0YTHuKGSS">pic.twitter.com/f0YTHuKGSS&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez 🚸 (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1059450575660687361?ref_src=twsrc%5Etfw">5 novembre 2018&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Running OpenBUGS in parallel</title><link>https://oliviergimenez.github.io/blog/run_openbugs_parallel/</link><pubDate>Sun, 14 Jan 2018 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/run_openbugs_parallel/</guid><description>&lt;img style="float:left;margin-right:10px;margin-top:10px;width:200px;margin-bottom:5px" src="https://oliviergimenez.github.io/img/parcomp.jpg">
Recently, I have been using `OpenBUGS` for some analyses that `JAGS` cannot do. However, `JAGS` can be run in parallel through [the `jagsUI` package](https://github.com/kenkellner/jagsUI), which can save you some precious time. So the question is how to run several chains in parallel with `OpenBUGS`.
&lt;p>Well, first you&amp;rsquo;ll need to install &lt;code>OpenBUGS&lt;/code> (if you&amp;rsquo;re on a Mac, check out
&lt;a href="https://oliviergimenez.github.io/post/run_openbugs_on_mac/" target="_blank" rel="noopener">this short tutorial&lt;/a>). Then, you&amp;rsquo;ll need to run &lt;code>OpenBUGS&lt;/code> from &lt;code>R&lt;/code> through the pacage &lt;code>R2OpenBUGS&lt;/code>, which you can install via:&lt;/p>
&lt;pre>&lt;code class="language-r">if(!require(R2OpenBUGS)) install.packages(&amp;quot;R2OpenBUGS&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Loading required package: R2OpenBUGS
&lt;/code>&lt;/pre>
&lt;h2 id="standard-analysis">Standard analysis&lt;/h2>
&lt;p>Now let&amp;rsquo;s run the classical &lt;code>BUGS&lt;/code> &lt;code>school&lt;/code> example:&lt;/p>
&lt;p>Load the &lt;code>OpenBUGS&lt;/code> Package&lt;/p>
&lt;pre>&lt;code class="language-r">library(R2OpenBUGS)
&lt;/code>&lt;/pre>
&lt;p>Load the data&lt;/p>
&lt;pre>&lt;code class="language-r">data(schools)
&lt;/code>&lt;/pre>
&lt;p>Define the model, write it to a text file and have a look&lt;/p>
&lt;pre>&lt;code class="language-r">nummodel &amp;lt;- function(){
for (j in 1:J){
y[j] ~ dnorm (theta[j], tau.y[j])
theta[j] ~ dnorm (mu.theta, tau.theta)
tau.y[j] &amp;lt;- pow(sigma.y[j], -2)}
mu.theta ~ dnorm (0.0, 1.0E-6)
tau.theta &amp;lt;- pow(sigma.theta, -2)
sigma.theta ~ dunif (0, 1000)
}
write.model(nummodel, &amp;quot;nummodel.txt&amp;quot;)
model.file1 = paste(getwd(),&amp;quot;nummodel.txt&amp;quot;, sep=&amp;quot;/&amp;quot;)
file.show(&amp;quot;nummodel.txt&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Prepare the data for input into OpenBUGS&lt;/p>
&lt;pre>&lt;code class="language-r">J &amp;lt;- nrow(schools)
y &amp;lt;- schools$estimate
sigma.y &amp;lt;- schools$sd
data &amp;lt;- list (&amp;quot;J&amp;quot;, &amp;quot;y&amp;quot;, &amp;quot;sigma.y&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Initialization of variables&lt;/p>
&lt;pre>&lt;code class="language-r">inits &amp;lt;- function(){
list(theta = rnorm(J, 0, 100), mu.theta = rnorm(1, 0, 100), sigma.theta = runif(1, 0, 100))}
&lt;/code>&lt;/pre>
&lt;p>Set the &lt;code>Wine&lt;/code> working directory and the directory to &lt;code>OpenBUGS&lt;/code>, and change the OpenBUGS.exe location as necessary:&lt;/p>
&lt;pre>&lt;code class="language-r">WINE=&amp;quot;/usr/local/Cellar/wine/2.0.4/bin/wine&amp;quot;
WINEPATH=&amp;quot;/usr/local/Cellar/wine/2.0.4/bin/winepath&amp;quot;
OpenBUGS.pgm=&amp;quot;/Applications/OpenBUGS323/OpenBUGS.exe&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>The are the parameters to save&lt;/p>
&lt;pre>&lt;code class="language-r">parameters = c(&amp;quot;theta&amp;quot;, &amp;quot;mu.theta&amp;quot;, &amp;quot;sigma.theta&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Run the model&lt;/p>
&lt;pre>&lt;code class="language-r">ptm &amp;lt;- proc.time()
schools.sim &amp;lt;- bugs(data, inits, model.file = model.file1,parameters=parameters,n.chains = 2, n.iter = 500000, n.burnin = 10000, OpenBUGS.pgm=OpenBUGS.pgm, WINE=WINE, WINEPATH=WINEPATH,useWINE=T)
elapsed_time &amp;lt;- proc.time() - ptm
elapsed_time
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## user system elapsed
## 50.835 2.053 55.010
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">print(schools.sim)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Inference for Bugs model at &amp;quot;/Users/oliviergimenez/Desktop/nummodel.txt&amp;quot;,
## Current: 2 chains, each with 5e+05 iterations (first 10000 discarded)
## Cumulative: n.sims = 980000 iterations saved
## mean sd 2.5% 25% 50% 75% 97.5% Rhat n.eff
## theta[1] 11.6 8.4 -1.9 6.1 10.5 15.8 32.0 1 370000
## theta[2] 8.0 6.4 -4.8 4.0 8.0 12.0 20.9 1 67000
## theta[3] 6.4 7.8 -11.3 2.2 6.8 11.2 20.9 1 55000
## theta[4] 7.7 6.6 -5.7 3.7 7.8 11.8 20.9 1 70000
## theta[5] 5.5 6.5 -8.8 1.6 5.9 9.8 17.1 1 26000
## theta[6] 6.2 6.9 -8.9 2.3 6.6 10.7 18.9 1 23000
## theta[7] 10.7 6.9 -1.4 6.0 10.1 14.7 26.2 1 480000
## theta[8] 8.7 7.9 -6.8 4.0 8.4 13.0 25.7 1 76000
## mu.theta 8.1 5.3 -2.0 4.7 8.1 11.4 18.5 1 30000
## sigma.theta 6.6 5.7 0.2 2.5 5.2 9.1 20.9 1 12000
## deviance 60.5 2.2 57.0 59.1 60.1 61.4 66.0 1 980000
##
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
##
## DIC info (using the rule, pD = Dbar-Dhat)
## pD = 2.8 and DIC = 63.2
## DIC is an estimate of expected predictive error (lower deviance is better).
&lt;/code>&lt;/pre>
&lt;h2 id="parallel-computations">Parallel computations&lt;/h2>
&lt;p>To run several chains in parallel, we&amp;rsquo;ll follow the steps described in
&lt;a href="http://www.petrkeil.com/?p=63" target="_blank" rel="noopener">this nice post&lt;/a>.&lt;/p>
&lt;pre>&lt;code class="language-r"># loading packages
library(snow)
library(snowfall)
# setting the number of CPUs to be 2
sfInit(parallel=TRUE, cpus=2)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Warning in searchCommandline(parallel, cpus = cpus, type
## = type, socketHosts = socketHosts, : Unknown option on
## commandline: rmarkdown::render('/Users/oliviergimenez/Desktop/
## run_openbugs_in_parallel.Rmd',~+~~+~encoding~+~
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## R Version: R version 3.4.3 (2017-11-30)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## snowfall 1.84-6.1 initialized (using snow 0.4-2): parallel execution on 2 CPUs.
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># and assigning the R2OpenBUGS library to each CPU
sfLibrary(R2OpenBUGS)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Library R2OpenBUGS loaded.
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Library R2OpenBUGS loaded in cluster.
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># create list of data
J &amp;lt;- nrow(schools)
y &amp;lt;- schools$estimate
sigma.y &amp;lt;- schools$sd
x.data &amp;lt;- list (J=J, y=y, sigma.y=sigma.y)
# creating separate directory for each CPU process
folder1 &amp;lt;- paste(getwd(), &amp;quot;/chain1&amp;quot;, sep=&amp;quot;&amp;quot;)
folder2 &amp;lt;- paste(getwd(), &amp;quot;/chain2&amp;quot;, sep=&amp;quot;&amp;quot;)
dir.create(folder1); dir.create(folder2);
# sinking the model into a file in each directory
for (folder in c(folder1, folder2))
{
sink(paste(folder, &amp;quot;/nummodel.txt&amp;quot;, sep=&amp;quot;&amp;quot;))
cat(&amp;quot;
model{
for (j in 1:J){
y[j] ~ dnorm (theta[j], tau.y[j])
theta[j] ~ dnorm (mu.theta, tau.theta)
tau.y[j] &amp;lt;- pow(sigma.y[j], -2)}
mu.theta ~ dnorm (0.0, 1.0E-6)
tau.theta &amp;lt;- pow(sigma.theta, -2)
sigma.theta ~ dunif (0, 1000)
}
&amp;quot;)
sink()
}
# defining the function that will run MCMC on each CPU
# Arguments:
# chain - will be 1 or 2
# x.data - the data list
# params - parameters to be monitored
parallel.bugs &amp;lt;- function(chain, x.data, params)
{
# a. defining directory for each CPU
sub.folder &amp;lt;- paste(getwd(),&amp;quot;/chain&amp;quot;, chain, sep=&amp;quot;&amp;quot;)
# b. specifying the initial MCMC values
inits &amp;lt;- function()list(theta = rnorm(x.data$J, 0, 100), mu.theta = rnorm(1, 0, 100), sigma.theta = runif(1, 0, 100))
# c. calling OpenBugs
# (you may need to change the OpenBUGS.pgm directory)
# je suis sous Mac, je fais tourner OpenBUGS via Wine
bugs(data=x.data, inits=inits, parameters.to.save=params,
n.iter = 500000, n.burnin = 10000, n.chains=1,
model.file=&amp;quot;nummodel.txt&amp;quot;, debug=FALSE, codaPkg=TRUE,
useWINE=TRUE, OpenBUGS.pgm = &amp;quot;/Applications/OpenBUGS323/OpenBUGS.exe&amp;quot;,
working.directory = sub.folder,
WINE=&amp;quot;/usr/local/Cellar/wine/2.0.4/bin/wine&amp;quot;,
WINEPATH=&amp;quot;/usr/local/Cellar/wine/2.0.4/bin/winepath&amp;quot;)
}
# setting the parameters to be monitored
params &amp;lt;- c(&amp;quot;theta&amp;quot;, &amp;quot;mu.theta&amp;quot;, &amp;quot;sigma.theta&amp;quot;)
# calling the sfLapply function that will run
# parallel.bugs on each of the 2 CPUs
ptm &amp;lt;- proc.time()
sfLapply(1:2, fun=parallel.bugs, x.data=x.data, params=params)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [[1]]
## [1] &amp;quot;/Users/oliviergimenez/Desktop/chain1/CODAchain1.txt&amp;quot;
##
## [[2]]
## [1] &amp;quot;/Users/oliviergimenez/Desktop/chain2/CODAchain1.txt&amp;quot;
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">elapsed_time = proc.time() - ptm
elapsed_time
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## user system elapsed
## 0.013 0.000 32.157
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># locating position of each CODA chain
chain1 &amp;lt;- paste(folder1, &amp;quot;/CODAchain1.txt&amp;quot;, sep=&amp;quot;&amp;quot;)
chain2 &amp;lt;- paste(folder2, &amp;quot;/CODAchain1.txt&amp;quot;, sep=&amp;quot;&amp;quot;)
# and, finally, getting the results
res &amp;lt;- read.bugs(c(chain1, chain2))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Abstracting deviance ... 490000 valid values
## Abstracting mu.theta ... 490000 valid values
## Abstracting sigma.theta ... 490000 valid values
## Abstracting theta[1] ... 490000 valid values
## Abstracting theta[2] ... 490000 valid values
## Abstracting theta[3] ... 490000 valid values
## Abstracting theta[4] ... 490000 valid values
## Abstracting theta[5] ... 490000 valid values
## Abstracting theta[6] ... 490000 valid values
## Abstracting theta[7] ... 490000 valid values
## Abstracting theta[8] ... 490000 valid values
## Abstracting deviance ... 490000 valid values
## Abstracting mu.theta ... 490000 valid values
## Abstracting sigma.theta ... 490000 valid values
## Abstracting theta[1] ... 490000 valid values
## Abstracting theta[2] ... 490000 valid values
## Abstracting theta[3] ... 490000 valid values
## Abstracting theta[4] ... 490000 valid values
## Abstracting theta[5] ... 490000 valid values
## Abstracting theta[6] ... 490000 valid values
## Abstracting theta[7] ... 490000 valid values
## Abstracting theta[8] ... 490000 valid values
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">summary(res)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Iterations = 10001:5e+05
## Thinning interval = 1
## Number of chains = 2
## Sample size per chain = 490000
##
## 1. Empirical mean and standard deviation for each variable,
## plus standard error of the mean:
##
## Mean SD Naive SE Time-series SE
## deviance 60.453 2.221 0.002243 0.005737
## mu.theta 8.109 5.261 0.005315 0.020596
## sigma.theta 6.610 5.682 0.005740 0.027336
## theta[1] 11.697 8.407 0.008493 0.027974
## theta[2] 8.023 6.395 0.006460 0.019264
## theta[3] 6.365 7.866 0.007946 0.022485
## theta[4] 7.735 6.601 0.006668 0.019766
## theta[5] 5.467 6.504 0.006570 0.022580
## theta[6] 6.234 6.885 0.006955 0.021332
## theta[7] 10.727 6.891 0.006961 0.023304
## theta[8] 8.648 7.892 0.007972 0.021541
##
## 2. Quantiles for each variable:
##
## 2.5% 25% 50% 75% 97.5%
## deviance 57.0200 59.120 60.040 61.430 65.99
## mu.theta -2.0600 4.784 8.066 11.410 18.50
## sigma.theta 0.2275 2.456 5.275 9.190 20.82
## theta[1] -1.8850 6.195 10.560 15.880 32.04
## theta[2] -4.8350 4.049 8.004 11.980 20.96
## theta[3] -11.4800 2.194 6.871 11.170 20.90
## theta[4] -5.7500 3.711 7.784 11.820 20.92
## theta[5] -8.8490 1.603 5.938 9.834 17.14
## theta[6] -8.8940 2.255 6.632 10.680 18.95
## theta[7] -1.3450 6.125 10.140 14.680 26.27
## theta[8] -6.8910 4.037 8.409 12.960 25.72
&lt;/code>&lt;/pre></description></item><item><title>Run OpenBUGS on a Mac</title><link>https://oliviergimenez.github.io/blog/run_openbugs_on_mac/</link><pubDate>Sat, 13 Jan 2018 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/run_openbugs_on_mac/</guid><description>&lt;img style="float:left;margin-right:10px;margin-top:10px;width:200px;margin-bottom:5px" src="https://oliviergimenez.github.io/img/bugs.jpg">
I had to use the good old `OpenBUGS` for some analyses that cannot be done in `JAGS`. Below are the steps to install `OpenBUGS` then to run it from your Mac either natively or from `R`. This tutorial is an adaptation of [this post](https://sites.google.com/site/mmeclimate/-bayesmet/openbugs-on-mac-os-x) and [that one](http://www.davideagle.org/r-2/bayesian-modeling-using-winbugs-and-openbugs/running-openbugs-on-mac-using-wine).
&lt;ol>
&lt;li>
&lt;p>If not done already, install
&lt;a href="https://brew.sh/" target="_blank" rel="noopener">Homebrew&lt;/a>. This program will make the installation of any other programs on your Mac so easy!&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Install
&lt;a href="https://www.winehq.org/" target="_blank" rel="noopener">Wine&lt;/a> which will allow you to run any Windows programs (.exe) on your Mac. To do so, start by
&lt;a href="http://blog.teamtreehouse.com/introduction-to-the-mac-os-x-command-line" target="_blank" rel="noopener">opening Terminal&lt;/a>, then type in the command: &lt;em>brew install wine&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Next, download the Windows version of &lt;code>OpenBUGS&lt;/code>
&lt;a href="https://www.mrc-bsu.cam.ac.uk/training/short-courses/bayescourse/download/" target="_blank" rel="noopener">here&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>To install &lt;code>OpenBUGS&lt;/code>, still in Terminal, go to the directory where the file was downloaded and type (you might need to unzip the file you downloaded first): &lt;em>wine OpenBUGS323setup.exe&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>OpenBUGS&lt;/code> is now installed and ready to be used! You can run it by first going to the directory where &lt;code>OpenBUGS&lt;/code> was installed. On my laptop, it can be achieved via the command: &lt;em>cd /Applications/OpenBUGS323&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Then, you just need to tye in the following command in the Terminal, and you should see an OpenBUGS windows poping up: &lt;em>wine OpenBUGS&lt;/em>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Now we would like to run &lt;code>OpenBUGS&lt;/code> from &lt;code>R&lt;/code>.&lt;/p>
&lt;ol start="7">
&lt;li>Install the package &lt;code>R2OpenBUGS&lt;/code> by typing in the &lt;code>R&lt;/code> console:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-r">if(!require(R2OpenBUGS)) install.packages(&amp;quot;R2OpenBUGS&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Loading required package: R2OpenBUGS
&lt;/code>&lt;/pre>
&lt;ol start="8">
&lt;li>Now let&amp;rsquo;s see whether everything works well by running the classical &lt;code>BUGS&lt;/code> &lt;code>school&lt;/code> example:&lt;/li>
&lt;/ol>
&lt;p>Load the &lt;code>OpenBUGS&lt;/code> Package&lt;/p>
&lt;pre>&lt;code class="language-r">library(R2OpenBUGS)
&lt;/code>&lt;/pre>
&lt;p>Load the data&lt;/p>
&lt;pre>&lt;code class="language-r">data(schools)
&lt;/code>&lt;/pre>
&lt;p>Define the model, write it to a text file and have a look&lt;/p>
&lt;pre>&lt;code class="language-r">nummodel &amp;lt;- function(){
for (j in 1:J){
y[j] ~ dnorm (theta[j], tau.y[j])
theta[j] ~ dnorm (mu.theta, tau.theta)
tau.y[j] &amp;lt;- pow(sigma.y[j], -2)}
mu.theta ~ dnorm (0.0, 1.0E-6)
tau.theta &amp;lt;- pow(sigma.theta, -2)
sigma.theta ~ dunif (0, 1000)
}
write.model(nummodel, &amp;quot;nummodel.txt&amp;quot;)
model.file1 = paste(getwd(),&amp;quot;nummodel.txt&amp;quot;, sep=&amp;quot;/&amp;quot;)
file.show(&amp;quot;nummodel.txt&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Prepare the data for input into OpenBUGS&lt;/p>
&lt;pre>&lt;code class="language-r">J &amp;lt;- nrow(schools)
y &amp;lt;- schools$estimate
sigma.y &amp;lt;- schools$sd
data &amp;lt;- list (&amp;quot;J&amp;quot;, &amp;quot;y&amp;quot;, &amp;quot;sigma.y&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Initialization of variables&lt;/p>
&lt;pre>&lt;code class="language-r">inits &amp;lt;- function(){
list(theta = rnorm(J, 0, 100), mu.theta = rnorm(1, 0, 100), sigma.theta = runif(1, 0, 100))}
&lt;/code>&lt;/pre>
&lt;p>Set the &lt;code>Wine&lt;/code> working directory and the directory to &lt;code>OpenBUGS&lt;/code>, and change the OpenBUGS.exe location as necessary:&lt;/p>
&lt;pre>&lt;code class="language-r">WINE=&amp;quot;/usr/local/Cellar/wine/2.0.4/bin/wine&amp;quot;
WINEPATH=&amp;quot;/usr/local/Cellar/wine/2.0.4/bin/winepath&amp;quot;
OpenBUGS.pgm=&amp;quot;/Applications/OpenBUGS323/OpenBUGS.exe&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>The are the parameters to save&lt;/p>
&lt;pre>&lt;code class="language-r">parameters = c(&amp;quot;theta&amp;quot;, &amp;quot;mu.theta&amp;quot;, &amp;quot;sigma.theta&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Run the model&lt;/p>
&lt;pre>&lt;code class="language-r">schools.sim &amp;lt;- bugs(data, inits, model.file = model.file1,parameters=parameters,n.chains = 3, n.iter = 1000, OpenBUGS.pgm=OpenBUGS.pgm, WINE=WINE, WINEPATH=WINEPATH,useWINE=T)
&lt;/code>&lt;/pre>
&lt;p>&lt;code>R&lt;/code> will pause. You might get a weird message starting by err:ole, just ignore it. When the run is complete, a prompt will reappear, then just type the following command to get the result:&lt;/p>
&lt;pre>&lt;code class="language-r">print(schools.sim)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Inference for Bugs model at &amp;quot;/Users/oliviergimenez/Desktop/nummodel.txt&amp;quot;,
## Current: 3 chains, each with 1000 iterations (first 500 discarded)
## Cumulative: n.sims = 1500 iterations saved
## mean sd 2.5% 25% 50% 75% 97.5% Rhat n.eff
## theta[1] 12.2 7.9 -1.3 7.5 11.2 16.4 32.1 1.0 62
## theta[2] 9.1 6.5 -4.0 5.1 9.4 13.2 21.4 1.0 150
## theta[3] 7.8 7.7 -9.4 3.6 8.5 12.6 21.1 1.0 360
## theta[4] 8.8 6.6 -4.5 4.5 9.2 13.3 20.4 1.0 110
## theta[5] 6.8 6.9 -8.2 2.3 7.5 11.4 17.7 1.0 410
## theta[6] 7.3 7.2 -8.6 2.7 8.2 11.8 18.9 1.0 190
## theta[7] 11.5 6.4 -0.3 7.5 11.2 15.7 25.0 1.1 42
## theta[8] 9.7 7.6 -4.7 5.1 9.6 14.4 25.1 1.0 130
## mu.theta 9.2 5.2 -1.2 5.8 9.3 12.5 18.2 1.0 88
## sigma.theta 5.9 5.6 0.2 1.7 4.4 8.5 20.2 1.1 51
## deviance 60.7 2.2 57.2 59.2 60.1 61.9 65.6 1.0 120
##
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
##
## DIC info (using the rule, pD = Dbar-Dhat)
## pD = 2.8 and DIC = 63.4
## DIC is an estimate of expected predictive error (lower deviance is better).
&lt;/code>&lt;/pre>
&lt;p>When run natively, &lt;code>WinBUGS&lt;/code> and &lt;code>OpenBUGS&lt;/code> have nice debugging capabilities; also, you can see what is going on, I mean the program reading the data, generating inits, and so on. To get the &lt;code>OpenBUGS&lt;/code> window with a bunch of useful info, just add &lt;code>debug=T&lt;/code> to the call of the &lt;code>bugs&lt;/code> function, and re-run the model&lt;/p>
&lt;pre>&lt;code class="language-r">schools.sim &amp;lt;- bugs(data, inits, model.file = model.file1,parameters=parameters,n.chains = 3, n.iter = 1000, OpenBUGS.pgm=OpenBUGS.pgm, WINE=WINE, WINEPATH=WINEPATH,useWINE=T,debug=T)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## arguments 'show.output.on.console', 'minimized' and 'invisible' are for Windows only
&lt;/code>&lt;/pre>
&lt;p>You will have to close the &lt;code>OpenBUGS&lt;/code> window to get the prompt back.&lt;/p></description></item><item><title>Simulating data with JAGS</title><link>https://oliviergimenez.github.io/blog/sim_with_jags/</link><pubDate>Thu, 23 Nov 2017 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/sim_with_jags/</guid><description>&lt;img style="float:left;margin-right:10px;margin-top:10px;width:200px;margin-bottom:5px" src="https://oliviergimenez.github.io/img/posterior_plots_lr.png">
Here, I illustrate the possibility to use `JAGS` to simulate data with two examples that might be of interest to population ecologists: first a linear regression, second a Cormack-Jolly-Seber capture-recapture model to estimate animal survival (formulated as a state-space model). The code is available from [GitHub](https://github.com/oliviergimenez/simul_with_jags).
&lt;p>Recently, I have been struggling with simulating data from complex hierarchical models. After several unsuccessful attempts in &lt;code>R&lt;/code>, I remembered the good old times when I was using &lt;code>WinBUGS&lt;/code> (more than 10 years already!) and the possibility to simulate data with it. I&amp;rsquo;m using &lt;code>JAGS&lt;/code> now, and a quick search in Google with &amp;lsquo;simulating data with jags&amp;rsquo; led me to
&lt;a href="https://www.georg-hosoya.de/wordpress/?p=799" target="_blank" rel="noopener">a complex example&lt;/a> and
&lt;a href="https://stackoverflow.com/questions/38295839/simulate-data-in-jags-r2jags" target="_blank" rel="noopener">a simple example&lt;/a>.&lt;/p>
&lt;p>Simulating data with &lt;code>JAGS&lt;/code> is convenient because you can use (almost) the same code for simulation and inference, and you can carry out simulation studies (bias, precision, interval coverage) in the same environment (namely &lt;code>JAGS&lt;/code>).&lt;/p>
&lt;h2 id="linear-regression-example">Linear regression example&lt;/h2>
&lt;p>We first load the packages we need for this tutorial:&lt;/p>
&lt;pre>&lt;code class="language-r">library(R2jags)
library(runjags)
library(mcmcplots)
&lt;/code>&lt;/pre>
&lt;p>Then straight to the point, let&amp;rsquo;s generate data from a linear regression model. The trick is to use a &lt;code>data&lt;/code> block, have the simplest &lt;code>model&lt;/code> block you could think of and pass the parameters as if they were data. Note that it&amp;rsquo;d be possible to use only a model block, see comment
&lt;a href="https://stackoverflow.com/questions/38295839/simulate-data-in-jags-r2jags" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;pre>&lt;code class="language-r">txtstring &amp;lt;- '
data{
# Likelihood:
for (i in 1:N){
y[i] ~ dnorm(mu[i], tau) # tau is precision (1 / variance)
mu[i] &amp;lt;- alpha + beta * x[i]
}
}
model{
fake &amp;lt;- 0
}
'
&lt;/code>&lt;/pre>
&lt;p>Here, &lt;code>alpha&lt;/code> and &lt;code>beta&lt;/code> are the intercept and slope, &lt;code>tau&lt;/code> the precision or the inverse of the variance, &lt;code>y&lt;/code> the response variable and &lt;code>x&lt;/code> the explanatory variable.&lt;/p>
&lt;p>We pick some values for the model parameters that we will use as data:&lt;/p>
&lt;pre>&lt;code class="language-r"># parameters for simulations
N = 30 # nb of observations
x &amp;lt;- 1:N # predictor
alpha = 0.5 # intercept
beta = 1 # slope
sigma &amp;lt;- .1 # residual sd
tau &amp;lt;- 1/(sigma*sigma) # precision
# parameters are treated as data for the simulation step
data&amp;lt;-list(N=N,x=x,alpha=alpha,beta=beta,tau=tau)
&lt;/code>&lt;/pre>
&lt;p>Now call &lt;code>JAGS&lt;/code>; note that we monitor the response variable instead of parameters as we would do when conducting standard inference:&lt;/p>
&lt;pre>&lt;code class="language-r"># run jags
out &amp;lt;- run.jags(txtstring, data = data,monitor=c(&amp;quot;y&amp;quot;),sample=1, n.chains=1, summarise=FALSE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Compiling rjags model...
## Calling the simulation using the rjags method...
## Note: the model did not require adaptation
## Burning in the model for 4000 iterations...
## Running the model for 1 iterations...
## Simulation complete
## Finished running the simulation
&lt;/code>&lt;/pre>
&lt;p>The output is a bit messy and needs to be formatted appropriately:&lt;/p>
&lt;pre>&lt;code class="language-r"># reformat the outputs
Simulated &amp;lt;- coda::as.mcmc(out)
Simulated
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Markov Chain Monte Carlo (MCMC) output:
## Start = 5001
## End = 5001
## Thinning interval = 1
## y[1] y[2] y[3] y[4] y[5] y[6] y[7] y[8]
## 5001 1.288399 2.52408 3.61516 4.583587 5.600675 6.566052 7.593407 8.457497
## y[9] y[10] y[11] y[12] y[13] y[14] y[15] y[16]
## 5001 9.70847 10.38035 11.5105 12.55048 13.49143 14.46356 15.45641 16.56148
## y[17] y[18] y[19] y[20] y[21] y[22] y[23]
## 5001 17.50935 18.51501 19.66197 20.49477 21.57079 22.6199 23.48232
## y[24] y[25] y[26] y[27] y[28] y[29] y[30]
## 5001 24.57923 25.47368 26.33674 27.46525 28.35525 29.60279 30.42952
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">dim(Simulated)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 1 30
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">dat = as.vector(Simulated)
dat
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 1.288399 2.524080 3.615160 4.583587 5.600675 6.566052 7.593407
## [8] 8.457497 9.708470 10.380351 11.510500 12.550482 13.491435 14.463564
## [15] 15.456410 16.561483 17.509350 18.515005 19.661969 20.494767 21.570790
## [22] 22.619899 23.482317 24.579228 25.473676 26.336736 27.465251 28.355248
## [29] 29.602791 30.429517
&lt;/code>&lt;/pre>
&lt;p>Now let&amp;rsquo;s fit the model we used to simulate to the data we just generated. I won&amp;rsquo;t go into the details and assume that the reader is familiar with &lt;code>JAGS&lt;/code> and linear regression.&lt;/p>
&lt;pre>&lt;code class="language-r"># specify model in BUGS language
model &amp;lt;-
paste(&amp;quot;
model {
# Likelihood:
for (i in 1:N){
y[i] ~ dnorm(mu[i], tau) # tau is precision (1 / variance)
mu[i] &amp;lt;- alpha + beta * x[i]
}
# Priors:
alpha ~ dnorm(0, 0.01) # intercept
beta ~ dnorm(0, 0.01) # slope
sigma ~ dunif(0, 100) # standard deviation
tau &amp;lt;- 1 / (sigma * sigma)
}
&amp;quot;)
writeLines(model,&amp;quot;lin_reg.jags&amp;quot;)
# data
jags.data &amp;lt;- list(y = dat, N = length(dat), x = x)
# initial values
inits &amp;lt;- function(){list(alpha = rnorm(1), beta = rnorm(1), sigma = runif(1,0,10))}
# parameters monitored
parameters &amp;lt;- c(&amp;quot;alpha&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
# MCMC settings
ni &amp;lt;- 10000
nt &amp;lt;- 6
nb &amp;lt;- 5000
nc &amp;lt;- 2
# call JAGS from R
res &amp;lt;- jags(jags.data, inits, parameters, &amp;quot;lin_reg.jags&amp;quot;, n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb, working.directory = getwd())
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## module glm loaded
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Compiling model graph
## Resolving undeclared variables
## Allocating nodes
## Graph information:
## Observed stochastic nodes: 30
## Unobserved stochastic nodes: 3
## Total graph size: 130
##
## Initializing model
&lt;/code>&lt;/pre>
&lt;p>Let&amp;rsquo;s have a look to the results and compare with the parameters we used to simulate the data (see above):&lt;/p>
&lt;pre>&lt;code class="language-r"># summarize posteriors
print(res, digits = 3)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Inference for Bugs model at &amp;quot;lin_reg.jags&amp;quot;, fit using jags,
## 2 chains, each with 10000 iterations (first 5000 discarded), n.thin = 6
## n.sims = 1668 iterations saved
## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat
## alpha 0.544 0.038 0.469 0.518 0.545 0.570 0.617 1.000
## beta 0.998 0.002 0.994 0.997 0.998 1.000 1.003 1.001
## sigma 0.102 0.015 0.078 0.091 0.100 0.110 0.138 1.002
## deviance -53.810 2.724 -56.867 -55.808 -54.516 -52.641 -46.676 1.001
## n.eff
## alpha 1700
## beta 1700
## sigma 780
## deviance 1700
##
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
##
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 3.7 and DIC = -50.1
## DIC is an estimate of expected predictive error (lower deviance is better).
&lt;/code>&lt;/pre>
&lt;p>Pretty close!&lt;/p>
&lt;p>Check convergence:&lt;/p>
&lt;pre>&lt;code class="language-r"># trace plots
traplot(res,c(&amp;quot;alpha&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://oliviergimenez.github.io/img/unnamed-chunk-8-1.png" alt="">&lt;!-- -->&lt;/p>
&lt;p>Plot the posterior distribution of the regression parameters and residual standard deviation:&lt;/p>
&lt;pre>&lt;code class="language-r"># posterior distributions
denplot(res,c(&amp;quot;alpha&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://oliviergimenez.github.io/img/unnamed-chunk-9-1.png" alt="">&lt;!-- -->&lt;/p>
&lt;h2 id="capture-recapture-example">Capture-recapture example&lt;/h2>
&lt;p>I now illustrate the use of &lt;code>JAGS&lt;/code> to simulate data from a Cormack-Jolly-Seber model with constant survival and recapture probabilities. I assume that the reader is familiar with this model and its formulation as a state-space model.&lt;/p>
&lt;p>Let&amp;rsquo;s simulate!&lt;/p>
&lt;pre>&lt;code class="language-r">txtstring &amp;lt;- '
data{
# Constant survival and recapture probabilities
for (i in 1:nind){
for (t in f[i]:(n.occasions-1)){
phi[i,t] &amp;lt;- mean.phi
p[i,t] &amp;lt;- mean.p
} #t
} #i
# Likelihood
for (i in 1:nind){
# Define latent state and obs at first capture
z[i,f[i]] &amp;lt;- 1
mu2[i,1] &amp;lt;- 1 * z[i,f[i]] # detection is 1 at first capture (&amp;quot;conditional on first capture&amp;quot;)
y[i,1] ~ dbern(mu2[i,1])
# then deal w/ subsequent occasions
for (t in (f[i]+1):n.occasions){
# State process
z[i,t] ~ dbern(mu1[i,t])
mu1[i,t] &amp;lt;- phi[i,t-1] * z[i,t-1]
# Observation process
y[i,t] ~ dbern(mu2[i,t])
mu2[i,t] &amp;lt;- p[i,t-1] * z[i,t]
} #t
} #i
}
model{
fake &amp;lt;- 0
}
'
&lt;/code>&lt;/pre>
&lt;p>Let&amp;rsquo;s pick some values for parameters and store them in a data list:&lt;/p>
&lt;pre>&lt;code class="language-r"># parameter for simulations
n.occasions = 10 # nb of occasions
nind = 100 # nb of individuals
mean.phi &amp;lt;- 0.8 # survival
mean.p &amp;lt;- 0.6 # recapture
f = rep(1,nind) # date of first capture
data&amp;lt;-list(n.occasions = n.occasions, mean.phi = mean.phi, mean.p = mean.p, f = f, nind = nind)
&lt;/code>&lt;/pre>
&lt;p>Now run &lt;code>JAGS&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">out &amp;lt;- run.jags(txtstring, data = data,monitor=c(&amp;quot;y&amp;quot;),sample=1, n.chains=1, summarise=FALSE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Compiling rjags model...
## Calling the simulation using the rjags method...
## Note: the model did not require adaptation
## Burning in the model for 4000 iterations...
## Running the model for 1 iterations...
## Simulation complete
## Finished running the simulation
&lt;/code>&lt;/pre>
&lt;p>Format the output:&lt;/p>
&lt;pre>&lt;code class="language-r">Simulated &amp;lt;- coda::as.mcmc(out)
dim(Simulated)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 1 1000
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">dat = matrix(Simulated,nrow=nind)
head(dat)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
## [1,] 1 1 0 0 0 0 0 0 0 0
## [2,] 1 1 1 1 0 0 0 0 0 0
## [3,] 1 0 0 0 0 0 0 0 0 0
## [4,] 1 0 0 0 0 0 0 0 0 0
## [5,] 1 0 0 0 0 0 0 0 0 0
## [6,] 1 1 1 1 0 0 1 0 1 1
&lt;/code>&lt;/pre>
&lt;p>Here I monitored only the detections and non-detections, but it is also possible to get the simulated values for the states, i.e. whether an individual is alive or dead at each occasion. You just need to amend the call to &lt;code>JAGS&lt;/code> with &lt;code>monitor=c(&amp;quot;y&amp;quot;,&amp;quot;x&amp;quot;)&lt;/code> and to amend the output accordingly.&lt;/p>
&lt;p>Now we fit a Cormack-Jolly-Seber model to the data we&amp;rsquo;ve just simulated, assuming constant parameters:&lt;/p>
&lt;pre>&lt;code class="language-r">model &amp;lt;-
paste(&amp;quot;
model {
# Priors and constraints
for (i in 1:nind){
for (t in f[i]:(n.occasions-1)){
phi[i,t] &amp;lt;- mean.phi
p[i,t] &amp;lt;- mean.p
} #t
} #i
mean.phi ~ dunif(0, 1) # Prior for mean survival
mean.p ~ dunif(0, 1) # Prior for mean recapture
# Likelihood
for (i in 1:nind){
# Define latent state at first capture
z[i,f[i]] &amp;lt;- 1
for (t in (f[i]+1):n.occasions){
# State process
z[i,t] ~ dbern(mu1[i,t])
mu1[i,t] &amp;lt;- phi[i,t-1] * z[i,t-1]
# Observation process
y[i,t] ~ dbern(mu2[i,t])
mu2[i,t] &amp;lt;- p[i,t-1] * z[i,t]
} #t
} #i
}
&amp;quot;)
writeLines(model,&amp;quot;cjs.jags&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Prepare the data:&lt;/p>
&lt;pre>&lt;code class="language-r"># vector with occasion of marking
get.first &amp;lt;- function(x) min(which(x!=0))
f &amp;lt;- apply(dat, 1, get.first)
# data
jags.data &amp;lt;- list(y = dat, f = f, nind = dim(dat)[1], n.occasions = dim(dat)[2])
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Initial values
known.state.cjs &amp;lt;- function(ch){
state &amp;lt;- ch
for (i in 1:dim(ch)[1]){
n1 &amp;lt;- min(which(ch[i,]==1))
n2 &amp;lt;- max(which(ch[i,]==1))
state[i,n1:n2] &amp;lt;- 1
state[i,n1] &amp;lt;- NA
}
state[state==0] &amp;lt;- NA
return(state)
}
inits &amp;lt;- function(){list(mean.phi = runif(1, 0, 1), mean.p = runif(1, 0, 1), z = known.state.cjs(dat))}
&lt;/code>&lt;/pre>
&lt;p>We&amp;rsquo;d like to carry out inference about survival and recapture probabilities:&lt;/p>
&lt;pre>&lt;code class="language-r">parameters &amp;lt;- c(&amp;quot;mean.phi&amp;quot;, &amp;quot;mean.p&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Standard MCMC settings:&lt;/p>
&lt;pre>&lt;code class="language-r">ni &amp;lt;- 10000
nt &amp;lt;- 6
nb &amp;lt;- 5000
nc &amp;lt;- 2
&lt;/code>&lt;/pre>
&lt;p>Ready to run &lt;code>JAGS&lt;/code>!&lt;/p>
&lt;pre>&lt;code class="language-r"># Call JAGS from R (BRT 1 min)
cjs &amp;lt;- jags(jags.data, inits, parameters, &amp;quot;cjs.jags&amp;quot;, n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb, working.directory = getwd())
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Compiling model graph
## Resolving undeclared variables
## Allocating nodes
## Graph information:
## Observed stochastic nodes: 900
## Unobserved stochastic nodes: 902
## Total graph size: 3707
##
## Initializing model
&lt;/code>&lt;/pre>
&lt;p>Summarize posteriors and compare to the values we used to simulate the data:&lt;/p>
&lt;pre>&lt;code class="language-r">print(cjs, digits = 3)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Inference for Bugs model at &amp;quot;cjs.jags&amp;quot;, fit using jags,
## 2 chains, each with 10000 iterations (first 5000 discarded), n.thin = 6
## n.sims = 1668 iterations saved
## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat
## mean.p 0.596 0.033 0.531 0.574 0.597 0.618 0.660 1.000
## mean.phi 0.784 0.021 0.742 0.770 0.785 0.799 0.824 1.001
## deviance 440.611 18.374 408.121 427.569 438.662 452.512 479.608 1.001
## n.eff
## mean.p 1700
## mean.phi 1700
## deviance 1700
##
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
##
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 168.9 and DIC = 609.5
## DIC is an estimate of expected predictive error (lower deviance is better).
&lt;/code>&lt;/pre>
&lt;p>Again pretty close!&lt;/p>
&lt;p>Trace plots&lt;/p>
&lt;pre>&lt;code class="language-r">traplot(cjs,c(&amp;quot;mean.phi&amp;quot;, &amp;quot;mean.p&amp;quot;))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://oliviergimenez.github.io/img/unnamed-chunk-21-1.png" alt="">&lt;!-- -->&lt;/p>
&lt;p>Posterior distribution plots:&lt;/p>
&lt;pre>&lt;code class="language-r">denplot(cjs,c(&amp;quot;mean.phi&amp;quot;, &amp;quot;mean.p&amp;quot;))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://oliviergimenez.github.io/img/unnamed-chunk-22-1.png" alt="">&lt;!-- -->&lt;/p></description></item><item><title>Fitting dynamic occupancy models with TMB</title><link>https://oliviergimenez.github.io/blog/occupancy_in_tmb/</link><pubDate>Thu, 24 Aug 2017 12:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/occupancy_in_tmb/</guid><description>&lt;img style="float:left;margin-right:10px;margin-top:10px;width:200px;margin-bottom:5px" src="https://oliviergimenez.github.io/img/occ_darryl.png">
Following my recent attempt to [fit a HMM model to capture-recapture data with TMB](https://oliviergimenez.github.io/post/multievent_in_tmb/) and the rather estonishing outcome (the code was > 300 time faster than the equivalent R code!), I was curious to add TMB to the [list of options I tried to fit dynamic occupancy models](https://oliviergimenez.github.io/post/occupancy_in_admb/). Well, the least I can say is that TMB is fast, damn fast!
&lt;p>The reasons for trying TMB were the same as before: TMB is said to be fast, allows for parallel computations, works with R, accomodates spatial stuff, allows easy implementation of random effects).&lt;/p>
&lt;p>I found materials on the internet to teach myself TMB, at least what I needed to implement a simple HMM model. See
&lt;a href="http://seananderson.ca/2014/10/17/tmb.html" target="_blank" rel="noopener">here&lt;/a> for a linear regression and a Gompertz state space model examples,
&lt;a href="https://www.youtube.com/watch?v=A5CLrhzNzVU" target="_blank" rel="noopener">here&lt;/a> for the same linear regression example on Youtube (that&amp;rsquo;s awesome!) and many other examples
&lt;a href="http://kaskr.github.io/adcomp/examples.html" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>The R code is available on my GitHub
&lt;a href="https://github.com/oliviergimenez/occupancy_tmb" target="_blank" rel="noopener">here&lt;/a>. TMB was&amp;hellip; wait for it&amp;hellip; &amp;gt; 300 times faster than ADMB, &amp;gt; 140 times than Unmarked and &amp;gt; 6000 times faster than Jags (although the comparison with the latter is a bit unfair I suppose). The results are available
&lt;a href="http://rpubs.com/ogimenez/301798" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>I&amp;rsquo;m new to TMB, but I&amp;rsquo;m gonna definitely dig into it. Congrats to
&lt;a href="https://github.com/kaskr/adcomp/graphs/contributors" target="_blank" rel="noopener">the developers&lt;/a>! Check out the
&lt;a href="http://tmb-project.org" target="_blank" rel="noopener">TMB website&lt;/a> as well as
&lt;a href="https://www.jstatsoft.org/article/view/v070i05" target="_blank" rel="noopener">the paper&lt;/a> that comes with it.&lt;/p></description></item><item><title>Fitting HMM/multievent capture-recapture models with TMB</title><link>https://oliviergimenez.github.io/blog/multievent_in_tmb/</link><pubDate>Mon, 21 Aug 2017 12:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/multievent_in_tmb/</guid><description>&lt;img style="float:left;margin-right:10px;margin-top:10px;" src="https://oliviergimenez.github.io/img/tmb.png">
Following my attempts to fit a HMM model to [capture-recapture data with Rcpp](http://localhost:1313/post/multievent_in_rcpp/) and to [occupancy data with ADMB](http://localhost:1313/post/occupancy_in_admb/), a few colleagues suggested TMB as a potential alternative for several reasons (fast, allows for parallel computations, works with R, accomodates spatial stuff, easy implementation of random effects, and probably other reasons that I don't know).
&lt;p>I found materials on the internet to teach myself TMB, at least what I needed to implement a simple HMM model. See
&lt;a href="http://seananderson.ca/2014/10/17/tmb.html" target="_blank" rel="noopener">here&lt;/a> for a linear regression and a Gompertz state space model examples,
&lt;a href="https://www.youtube.com/watch?v=A5CLrhzNzVU" target="_blank" rel="noopener">here&lt;/a> for the same linear regression example on Youtube (that&amp;rsquo;s awesome!) and many other examples
&lt;a href="http://kaskr.github.io/adcomp/examples.html" target="_blank" rel="noopener">here&lt;/a>. However, I got stuck and posted my desperate request for help on the
&lt;a href="https://groups.google.com/forum/#!forum/tmb-users" target="_blank" rel="noopener">TMB forum&lt;/a>. Guess what, I got an answer less than a few hours after - thank you Mollie Brooks!&lt;/p>
&lt;p>The R code is available on my GitHub
&lt;a href="https://github.com/oliviergimenez/hmm_tmb" target="_blank" rel="noopener">here&lt;/a>. Minimizing the deviance coded with TMB was&amp;hellip; wait for it&amp;hellip; &amp;gt; 300 times faster than using the deviance coded in standard R.&lt;/p>
&lt;p>Hope this is useful.&lt;/p></description></item><item><title>Fitting multievent capture-recapture models with Rcpp</title><link>https://oliviergimenez.github.io/blog/multievent_in_rcpp/</link><pubDate>Fri, 11 Aug 2017 12:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/multievent_in_rcpp/</guid><description>&lt;img style="float:left;margin-right:10px;margin-top:10px;" src="https://oliviergimenez.github.io/img/seamless.png">
Following my previous post on [using ADMB to fit hidden Markov models](https://oliviergimenez.github.io/post/occupancy_in_admb/), I took some time to learn how to use Rcpp ([Eddelbuettel &amp; Francois 2011](https://www.jstatsoft.org/article/view/v040i08); [Eddelbuettel 2013](http://www.springer.com/us/book/9781461468677)), a package that gives friendly access to the power of C++ and increase the speed of your R programs. Kudos to Dirk Eddelbuettel, Romain Francois and their colleagues, Rcpp is awesome!
&lt;p>I started with the excellent
&lt;a href="http://adv-r.had.co.nz/Rcpp.html" target="_blank" rel="noopener">Rcpp chapter&lt;/a> in the
&lt;a href="http://adv-r.had.co.nz/" target="_blank" rel="noopener">Advanced R&lt;/a> book by Hadley Wickham which I complemented with the various
&lt;a href="https://cran.r-project.org/web/packages/Rcpp/index.html" target="_blank" rel="noopener">vignettes&lt;/a> that come with the package. As always, I googled the problems I had and often ended up finding the solution on
&lt;a href="https://stackoverflow.com/" target="_blank" rel="noopener">stackoverflow&lt;/a>. The
&lt;a href="http://lists.r-forge.r-project.org/mailman/listinfo/rcpp-devel" target="_blank" rel="noopener">rcpp-devel discussion list&lt;/a> is the place where questions should be asked about Rcpp.&lt;/p>
&lt;p>My objective was to implement the likelihood of a relatively simple multievent capture-recapture model (
&lt;a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1541-0420.2005.00318.x/abstract" target="_blank" rel="noopener">Pradel 2005&lt;/a>) with Rcpp. I recycled some R code I had and a dataset on shearwaters I used in a paper (
&lt;a href="https://dl.dropboxusercontent.com/u/23160641/my-pubs/Gimenezetal2012TPB.pdf" target="_blank" rel="noopener">Gimenez et al. 2012&lt;/a>).&lt;/p>
&lt;p>The R code is available on my GitHub
&lt;a href="https://github.com/oliviergimenez/multieventRcpp" target="_blank" rel="noopener">here&lt;/a>. To run it, you just need to type Rcpp::sourceCpp(&amp;lsquo;multi event.cpp&amp;rsquo;) in the console. I&amp;rsquo;m convinced that the code can be improved, but this simple exercise showed that minimizing the deviance coded with Rcpp and calculating the Hessian was 10 times faster than using the deviance coded in standard R.&lt;/p>
&lt;p>Next steps will be to go for RcppArmadillo for matrix computations and RcppNumerical for optimisation (and numerical integration for random effects).&lt;/p>
&lt;p>Hope this is useful.&lt;/p>
&lt;p>&lt;strong>Update:&lt;/strong> Following an advice from Romain Francois and Dirk Eddelbuettel (the Rcpp gurus), I have switched to
&lt;a href="https://cran.r-project.org/web/packages/RcppArmadillo/index.html" target="_blank" rel="noopener">RcppArmadillo&lt;/a> to rely on the code developed by professionals and decades of testing. Now the RcppArmadillo code is 50 times faster than basic R! The code is available on
&lt;a href="https://github.com/oliviergimenez/multieventRcpp" target="_blank" rel="noopener">my GitHub&lt;/a>.&lt;/p></description></item><item><title>Fitting occupancy models in ADMB</title><link>https://oliviergimenez.github.io/blog/occupancy_in_admb/</link><pubDate>Sun, 06 Aug 2017 12:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/occupancy_in_admb/</guid><description>&lt;img style="float:left;margin-right:10px;margin-top:10px;margin-bottom:10px;" src="https://oliviergimenez.github.io/img/admb.png">
Some time ago, a student of mine got stuck when fitting dynamic occupancy models to real data in Jags because of the computational burden.
&lt;p>We had a dataset with several thousands sites, more than 20 seasons and 4 surveys per season (yeah!).&lt;/p>
&lt;p>We thought of using Unmarked instead (the likelihood is written in C++ and used through Rcpp), but dynamic models with false positives and/or random effects are not (yet?) implemented, and we were interested in considering both in our analysis. Some years ago, I had the opportunity to learn ADMB in a NCEAS meeting (thanks Hans Skaug!), I thought I would give it a try. ADMB allows you to write down any likelihood functions yourself and to incorporate random effects in an efficient way. It&amp;rsquo;s known to be fast for reasons I won&amp;rsquo;t go into here. Last but not least, ADMB can be run from R like JAGS and Unmarked (thanks Ben Bolker!).&lt;/p>
&lt;p>Here we go. I first simulate some data, then fit a dynamic model using ADMB, JAGS and Unmarked and finally perform a quick benchmarking. I&amp;rsquo;m going for a standard dynamic model, because the aims are i) to verify that JAGS is slower than Unmarked, ii) that ADMB is closer to Unmarked than JAGS in terms of time computation. If ii) is verified, then it will be worth the effort coding everything in ADMB.&lt;/p>
&lt;p>The results are available on RPub
&lt;a href="http://rpubs.com/ogimenez/297167" target="_blank" rel="noopener">here&lt;/a>. The code is available on GitHub
&lt;a href="https://github.com/oliviergimenez/occupancy_in_ADMB" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>Hope this is useful.&lt;/p></description></item><item><title>Working group on animal/human demography</title><link>https://oliviergimenez.github.io/blog/working_group_demo/</link><pubDate>Thu, 26 Jan 2017 12:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/working_group_demo/</guid><description>&lt;p>We organised a 2-day workshop on the metrics of longevity used in human and
animal demography. The idea is to explore potential bridges between the two fields.
Next meeting in April. The group is led by S. Cubaynes, a former PhD student of mine,
who now holds a lecturer position at Montpellier University.&lt;/p></description></item><item><title>Workshop on issues in fitting hierarchical models in ecology</title><link>https://oliviergimenez.github.io/blog/working_group_hm/</link><pubDate>Mon, 28 Nov 2016 12:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/working_group_hm/</guid><description>&lt;p>Frederic Gosselin, Etienne Rivot and I organised a 2-day workshop on issues in
fitting hierarchical models in ecology. I gave a talk on &amp;ldquo;Local minima and multistate
capture-recapture models&amp;rdquo;, slides and R code available on
&lt;a href="https://github.com/oliviergimenez/multistate_local_minima" target="_blank" rel="noopener">GitHub&lt;/a>.&lt;/p>
&lt;iframe src="https://widgets.figshare.com/articles/4833524/embed?show_title=1" width="568" height="351" frameborder="0">&lt;/iframe>
&lt;p>The idea is to consider several problematic case studies and explore the issues using
several computing platforms (R, Jags, Nimble, Stan, Admb). Next meeting in May.&lt;/p></description></item><item><title>Analysing the social Star Wars network in The Attack of the Clones with R</title><link>https://oliviergimenez.github.io/blog/starwars_network/</link><pubDate>Sun, 07 Aug 2016 12:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/starwars_network/</guid><description>&lt;p>This is a free adaptation of two (very) clever analyses made by others:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>
&lt;a href="http://evelinag.com/blog/2015/12-15-star-wars-social-network" target="_blank" rel="noopener">The Star Wars Social Network by Evelina Gabasov&lt;/a> in which program F# was mostly used to analyse the Star wars social networks&lt;/p>
&lt;/li>
&lt;li>
&lt;p>
&lt;a href="http://varianceexplained.org/r/love-actually-network/" target="_blank" rel="noopener">Analyzing networks of characters in &amp;lsquo;Love Actually&amp;rsquo; by David Robinson&lt;/a> in which R was used to analyse the links between the characters of the movie Love Actually.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>The aim here is to try and reproduce Evelina&amp;rsquo;s analysis using R only, using David&amp;rsquo;s contribution plus several tweaks I found here and there on the internet. The R code and data are available on my
&lt;a href="https://github.com/oliviergimenez/starwars_network" target="_blank" rel="noopener">GitHub page&lt;/a>.&lt;/p>
&lt;p>&lt;em>Disclaimer&lt;/em>: The original blog posts are awesome and full of relevant details, check them out! My objective here was to teach myself how to manipulate data using trendy R packages and do some network analyses. Some comments below have been copied and pasted from these blogs, the credits entirely go to the authors Evelina and David. Last but not least, my code comes with mistakes probably.&lt;/p>
&lt;h1 id="read-and-format-data">Read and format data&lt;/h1>
&lt;p>First, read in data. I found the movie script in doc format
&lt;a href="theforce.net/timetales/ep2se.doc">here&lt;/a>, which I converted in txt format for convenience. Then, apply various treatments to have the data ready for analysis. I use the old school way for modifying the original dataframe.
&lt;a href="https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf" target="_blank" rel="noopener">Piping&lt;/a> would have made the code more readable, but I do not feel confident with this approach yet.&lt;/p>
&lt;pre>&lt;code class="language-r"># load convenient packages
library(dplyr)
library(stringr)
library(tidyr)
# read file line by line
raw &amp;lt;- readLines(&amp;quot;attack-of-the-clones.txt&amp;quot;)
# create data frame
lines &amp;lt;- data_frame(raw = raw)
# get rid of leading and trailing white spaces
# http://stackoverflow.com/questions/2261079/how-to-trim-leading-and-trailing-whitespace-in-r
trim &amp;lt;- function (x) gsub(&amp;quot;^\\s+|\\s+$&amp;quot;, &amp;quot;&amp;quot;, x)
lines &amp;lt;- mutate(lines,raw=trim(raw))
# get rid of the empty lines
lines2 &amp;lt;- filter(lines, raw != &amp;quot;&amp;quot;)
# detect scenes: begin by EXT. or INT.
lines3 &amp;lt;- mutate(lines2, is_scene = str_detect(raw, &amp;quot;T.&amp;quot;),scene = cumsum(is_scene))
# drop lines that start with EXT. or INT.
lines4 &amp;lt;- filter(lines3,!is_scene)
# distinguish characters from what they say
lines5 &amp;lt;- separate(lines4, raw, c(&amp;quot;speaker&amp;quot;, &amp;quot;dialogue&amp;quot;), sep = &amp;quot;:&amp;quot;, fill = &amp;quot;left&amp;quot;,extra='drop')
# read in aliases (from Evelina's post)
aliases &amp;lt;- read.table('aliases.csv',sep=',',header=T,colClasses = &amp;quot;character&amp;quot;)
aliases$Alias
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] &amp;quot;BEN&amp;quot; &amp;quot;SEE-THREEPIO&amp;quot; &amp;quot;THREEPIO&amp;quot; &amp;quot;ARTOO-DETOO&amp;quot;
## [5] &amp;quot;ARTOO&amp;quot; &amp;quot;PALPATINE&amp;quot; &amp;quot;DARTH SIDIOUS&amp;quot; &amp;quot;BAIL&amp;quot;
## [9] &amp;quot;MACE&amp;quot; &amp;quot;WINDU&amp;quot; &amp;quot;MACE-WINDU&amp;quot; &amp;quot;NUTE&amp;quot;
## [13] &amp;quot;AUNT BERU&amp;quot; &amp;quot;DOOKU&amp;quot; &amp;quot;BOBA&amp;quot; &amp;quot;JANGO&amp;quot;
## [17] &amp;quot;PANAKA&amp;quot; &amp;quot;NUTE&amp;quot; &amp;quot;KI-ADI&amp;quot; &amp;quot;BIBBLE&amp;quot;
## [21] &amp;quot;BIB&amp;quot; &amp;quot;CHEWIE&amp;quot; &amp;quot;VADER&amp;quot;
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">aliases$Name
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] &amp;quot;OBI-WAN&amp;quot; &amp;quot;C-3PO&amp;quot; &amp;quot;C-3PO&amp;quot; &amp;quot;R2-D2&amp;quot;
## [5] &amp;quot;R2-D2&amp;quot; &amp;quot;EMPEROR&amp;quot; &amp;quot;EMPEROR&amp;quot; &amp;quot;BAIL ORGANA&amp;quot;
## [9] &amp;quot;MACE WINDU&amp;quot; &amp;quot;MACE WINDU&amp;quot; &amp;quot;MACE WINDU&amp;quot; &amp;quot;NUTE GUNRAY&amp;quot;
## [13] &amp;quot;BERU&amp;quot; &amp;quot;COUNT DOOKU&amp;quot; &amp;quot;BOBA FETT&amp;quot; &amp;quot;JANGO FETT&amp;quot;
## [17] &amp;quot;CAPTAIN PANAKA&amp;quot; &amp;quot;NUTE GUNRAY&amp;quot; &amp;quot;KI-ADI-MUNDI&amp;quot; &amp;quot;SIO BIBBLE&amp;quot;
## [21] &amp;quot;BIB FORTUNA&amp;quot; &amp;quot;CHEWBACCA&amp;quot; &amp;quot;DARTH VADER&amp;quot;
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># assign unique name to characters
# http://stackoverflow.com/questions/28593265/is-there-a-function-like-switch-which-works-inside-of-dplyrmutate
multipleReplace &amp;lt;- function(x, what, by) {
stopifnot(length(what)==length(by))
ind &amp;lt;- match(x, what)
ifelse(is.na(ind),x,by[ind])
}
lines6 &amp;lt;- mutate(lines5,speaker=multipleReplace(speaker,what=aliases$Alias,by=aliases$Name))
# read in actual names (from Evelina's post)
actual.names &amp;lt;- read.csv('characters.csv',header=F,colClasses = &amp;quot;character&amp;quot;)
actual.names &amp;lt;- c(as.matrix(actual.names))
# filter out non-characters
lines7 &amp;lt;- filter(lines6,speaker %in% actual.names)
# group by scene
lines8 &amp;lt;- group_by(lines7, scene, line = cumsum(!is.na(speaker)))
lines9 &amp;lt;- summarize(lines8, speaker = speaker[1], dialogue = str_c(dialogue, collapse = &amp;quot; &amp;quot;))
# Count the lines-per-scene-per-character
# Turn the result into a binary speaker-by-scene matrix
by_speaker_scene &amp;lt;- count(lines9, scene, speaker)
by_speaker_scene
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 447 x 3
## # Groups: scene [321]
## scene speaker n
## &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
## 1 26 PADME 1
## 2 27 PADME 1
## 3 29 PADME 1
## 4 48 PADME 1
## 5 50 PADME 2
## 6 66 MACE WINDU 1
## 7 67 MACE WINDU 1
## 8 69 YODA 1
## 9 70 MACE WINDU 1
## 10 74 YODA 1
## # ... with 437 more rows
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">library(reshape2)
speaker_scene_matrix &amp;lt;-acast(by_speaker_scene , speaker ~ scene, fun.aggregate = length)
dim(speaker_scene_matrix)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 19 321
&lt;/code>&lt;/pre>
&lt;h1 id="analyses">Analyses&lt;/h1>
&lt;h2 id="hierarchical-clustering">Hierarchical clustering&lt;/h2>
&lt;pre>&lt;code class="language-r">norm &amp;lt;- speaker_scene_matrix / rowSums(speaker_scene_matrix)
h &amp;lt;- hclust(dist(norm, method = &amp;quot;manhattan&amp;quot;))
plot(h)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://oliviergimenez.github.io/img/starwars_network_files/figure-html/unnamed-chunk-2-1.png" alt="">&lt;!-- -->&lt;/p>
&lt;h2 id="timeline">Timeline&lt;/h2>
&lt;p>Use tree to give an ordering that puts similar characters close together&lt;/p>
&lt;pre>&lt;code class="language-r">ordering &amp;lt;- h$labels[h$order]
ordering
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] &amp;quot;MACE WINDU&amp;quot; &amp;quot;YODA&amp;quot; &amp;quot;SHMI&amp;quot; &amp;quot;QUI-GON&amp;quot; &amp;quot;PLO KOON&amp;quot;
## [6] &amp;quot;LAMA SU&amp;quot; &amp;quot;OBI-WAN&amp;quot; &amp;quot;BAIL ORGANA&amp;quot; &amp;quot;JAR JAR&amp;quot; &amp;quot;POGGLE&amp;quot;
## [11] &amp;quot;ANAKIN&amp;quot; &amp;quot;PADME&amp;quot; &amp;quot;CLIEGG&amp;quot; &amp;quot;BERU&amp;quot; &amp;quot;OWEN&amp;quot;
## [16] &amp;quot;SIO BIBBLE&amp;quot; &amp;quot;RUWEE&amp;quot; &amp;quot;JOBAL&amp;quot; &amp;quot;SOLA&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>This ordering can be used to make other graphs more informative. For instance, we can visualize a timeline of all scenes:&lt;/p>
&lt;pre>&lt;code class="language-r">scenes &amp;lt;- filter(by_speaker_scene, n() &amp;gt; 1) # scenes with &amp;gt; 1 character
scenes2 &amp;lt;- ungroup(scenes)
scenes3 &amp;lt;- mutate(scenes2, scene = as.numeric(factor(scene)),
character = factor(speaker, levels = ordering))
library(ggplot2)
ggplot(scenes3, aes(scene, character)) +
geom_point() +
geom_path(aes(group = scene))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://oliviergimenez.github.io/img/starwars_network_files/figure-html/unnamed-chunk-4-1.png" alt="">&lt;!-- -->&lt;/p>
&lt;p>Create a cooccurence matrix (see
&lt;a href="http://stackoverflow.com/questions/13281303/creating-co-occurrence-matrix" target="_blank" rel="noopener">here&lt;/a>) containing how many times two characters share scenes&lt;/p>
&lt;pre>&lt;code class="language-r">cooccur &amp;lt;- speaker_scene_matrix %*% t(speaker_scene_matrix)
heatmap(cooccur)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://oliviergimenez.github.io/img/starwars_network_files/figure-html/unnamed-chunk-5-1.png" alt="">&lt;!-- -->&lt;/p>
&lt;h2 id="social-network-analyses">Social network analyses&lt;/h2>
&lt;h3 id="graphical-representation-of-the-network">Graphical representation of the network&lt;/h3>
&lt;p>Here the nodes represent characters in the movies. The characters are connected by a link if they both speak in the same scene. And the more the characters speak together, the thicker the link between them.&lt;/p>
&lt;pre>&lt;code class="language-r">library(igraph)
g &amp;lt;- graph.adjacency(cooccur, weighted = TRUE, mode = &amp;quot;undirected&amp;quot;, diag = FALSE)
plot(g, edge.width = E(g)$weight)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://oliviergimenez.github.io/img/starwars_network_files/figure-html/unnamed-chunk-6-1.png" alt="">&lt;!-- -->&lt;/p>
&lt;p>Compute standard network features, degree and betweeness.&lt;/p>
&lt;pre>&lt;code class="language-r">degree(g)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## ANAKIN BAIL ORGANA BERU CLIEGG JAR JAR JOBAL
## 12 1 4 4 4 4
## LAMA SU MACE WINDU OBI-WAN OWEN PADME PLO KOON
## 1 5 6 4 12 0
## POGGLE QUI-GON RUWEE SHMI SIO BIBBLE SOLA
## 1 1 4 1 0 4
## YODA
## 4
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">betweenness(g)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## ANAKIN BAIL ORGANA BERU CLIEGG JAR JAR JOBAL
## 42.600000 0.000000 1.750000 0.500000 22.000000 0.000000
## LAMA SU MACE WINDU OBI-WAN OWEN PADME PLO KOON
## 0.000000 18.366667 15.000000 5.250000 55.133333 0.000000
## POGGLE QUI-GON RUWEE SHMI SIO BIBBLE SOLA
## 0.000000 0.000000 0.700000 0.000000 0.000000 5.000000
## YODA
## 3.366667
&lt;/code>&lt;/pre>
&lt;p>To get a nicer representation of the network, see
&lt;a href="http://tagteam.harvard.edu/hub_feeds/1981/feed_items/1388531" target="_blank" rel="noopener">here&lt;/a> and the formating from igraph to d3Network. Below is the code you’d need:&lt;/p>
&lt;pre>&lt;code class="language-r">library(d3Network)
library(networkD3)
sg &amp;lt;- simplify(g)
df &amp;lt;- get.edgelist(g, names=TRUE)
df &amp;lt;- as.data.frame(df)
colnames(df) &amp;lt;- c('source', 'target')
df$value &amp;lt;- rep(1, nrow(df))
# get communities
fc &amp;lt;- fastgreedy.community(g)
com &amp;lt;- membership(fc)
node.info &amp;lt;- data.frame(name=names(com), group=as.vector(com))
links &amp;lt;- data.frame(source=match(df$source, node.info$name)-1,target=match(df$target, node.info$name)-1,value=df$value)
forceNetwork(Links = links, Nodes = node.info,Source = &amp;quot;source&amp;quot;, Target = &amp;quot;target&amp;quot;,Value = &amp;quot;value&amp;quot;, NodeID = &amp;quot;name&amp;quot;,Group = &amp;quot;group&amp;quot;, opacity = 1, opacityNoHover=1)
&lt;/code>&lt;/pre>
&lt;p>The nodes represent characters in the movies. The characters are connected by a link if they both speak in the same scene. The colors are for groups obtained by some algorithms.&lt;/p></description></item><item><title>Self teaching reproducible research</title><link>https://oliviergimenez.github.io/blog/reproducible_research/</link><pubDate>Sun, 10 Jul 2016 12:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/reproducible_research/</guid><description>&lt;p>I decided to teach myself how to do proper reproducible research. Many reasons to
that: save time on the mid/long term, make my analyses open and criticizable, share with others, &amp;hellip;&lt;/p>
&lt;p>There are tons of resources on the web. I use the
&lt;a href="http://kbroman.org/pages/tutorials.html" target="_blank" rel="noopener">tutorials&lt;/a>
cooked by guru
&lt;a href="http://kbroman.org/" target="_blank" rel="noopener">Karl Broman&lt;/a>.
For people like me who learned S-plus, he has some
&lt;a href="http://kbroman.org/hipsteR/" target="_blank" rel="noopener">advice&lt;/a> to switch to modern tools.
Among others, I try and use more and more RStudio in connection with KnitR and R Markdown and
share my codes on
&lt;a href="https://github.com/oliviergimenez" target="_blank" rel="noopener">GitHub&lt;/a>. I am more a Fortran guy,
but Rcpp makes me wonder about C++. Version control, piping and the tidy universe are
not yet entirely familiar to me, I’m making baby steps (or grandpa steps I should say). Let’s see how it goes.&lt;/p></description></item><item><title>New kids on the Bayesian block</title><link>https://oliviergimenez.github.io/blog/nimble/</link><pubDate>Thu, 10 Jul 2014 12:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/nimble/</guid><description>&lt;p>I attended Daniel Turek&amp;rsquo;s talk at ISEC about &lt;a href="http://r-nimble.org/" target="_blank">NIMBLE&lt;/a>
a neat alternative to WinBUGS and JAGS. It is developed by
&lt;a href="http://nature.berkeley.edu/~pdevalpine/" target="_blank">Perry de Valpine&amp;rsquo;s
group&lt;/a> at Berkeley and &lt;em>&amp;lsquo;lets you use BUGS models natively in R, program functions
that use them, and compile everything via C++ for faster computing&amp;rsquo;.&lt;/em> I played around
with NIMBLE a bit, &lt;a href="https://dl.dropboxusercontent.com/u/23160641/my-codes/cjs-nimble.R" target="_blank">here&lt;/a>
is an example of fitting a classic capture-recapture model to simulated data - thanks to Perry
and Daniel for their help! NIMBLE seems a lot faster than its competitors, and much more flexible.
I&amp;rsquo;ll continue my investigations with more complex models - stay tuned.&lt;/p></description></item></channel></rss>