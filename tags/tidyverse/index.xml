<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>tidyverse | Olivier Gimenez</title><link>https://oliviergimenez.github.io/tags/tidyverse/</link><atom:link href="https://oliviergimenez.github.io/tags/tidyverse/index.xml" rel="self" type="application/rss+xml"/><description>tidyverse</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Olivier Gimenez 2021</copyright><lastBuildDate>Fri, 18 Dec 2020 00:00:00 +0000</lastBuildDate><image><url>https://oliviergimenez.github.io/img/flyfishing.jpg</url><title>tidyverse</title><link>https://oliviergimenez.github.io/tags/tidyverse/</link></image><item><title>Workshop on reproducible science</title><link>https://oliviergimenez.github.io/blog/reproscience2020/</link><pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/reproscience2020/</guid><description>&lt;p>Workshop to come on reproducible science in our lab.&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">ðŸ§‘â€ðŸ”¬ðŸ’»â™»ï¸ Planning a 1-day workshop on reproducible science for our lab &lt;a href="https://twitter.com/cefemontpellier?ref_src=twsrc%5Etfw">@cefemontpellier&lt;/a>. We&amp;#39;ll use R and RStudio, Git, GitHub, R Markdown, tidyverse and sf ðŸ¤©&lt;br>&lt;br>Material here &lt;a href="https://t.co/QApKQsl1FU">https://t.co/QApKQsl1FU&lt;/a> &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> &lt;a href="https://twitter.com/hashtag/ReproducibleScience?src=hash&amp;amp;ref_src=twsrc%5Etfw">#ReproducibleScience&lt;/a> &lt;a href="https://twitter.com/twitthair1?ref_src=twsrc%5Etfw">@twitthair1&lt;/a> &lt;br>&lt;br>pix by &lt;a href="https://twitter.com/scriberian?ref_src=twsrc%5Etfw">@scriberian&lt;/a> &lt;a href="https://t.co/LFBwZmelit">pic.twitter.com/LFBwZmelit&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez ðŸ–– (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1339896916109373440?ref_src=twsrc%5Etfw">December 18, 2020&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Text mining of the ISEC2020 abstracts</title><link>https://oliviergimenez.github.io/blog/textminingisec/</link><pubDate>Mon, 06 Jul 2020 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/textminingisec/</guid><description>&lt;p>Quick and dirty text mining of the ISEC2020 abstracts.&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">Quick and dirty text mining of the &lt;a href="https://twitter.com/isec2020?ref_src=twsrc%5Etfw">@isec2020&lt;/a> &lt;a href="https://twitter.com/hashtag/vISEC2020?src=hash&amp;amp;ref_src=twsrc%5Etfw">#vISEC2020&lt;/a> abstracts using awesome &amp;#39;Text Mining with R - A Tidy Approach&amp;#39; by &lt;a href="https://twitter.com/juliasilge?ref_src=twsrc%5Etfw">@juliasilge&lt;/a> &amp;amp; &lt;a href="https://twitter.com/drob?ref_src=twsrc%5Etfw">@drob&lt;/a> &lt;a href="https://t.co/qwugbZevDY">https://t.co/qwugbZevDY&lt;/a> - codes &amp;amp; data âž¡ï¸ &lt;a href="https://t.co/Y4adeWUpiW">https://t.co/Y4adeWUpiW&lt;/a> &lt;a href="https://t.co/bPjAgNwsWL">pic.twitter.com/bPjAgNwsWL&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez ðŸ–– (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1279911493874716673?ref_src=twsrc%5Etfw">July 5, 220&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>DÃ©prÃ©dations par le loup en France</title><link>https://oliviergimenez.github.io/blog/coadapht/</link><pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/coadapht/</guid><description>&lt;p>Une analyse descriptive du phÃ©nomÃ¨ne de concentration dâ€™attaques de loup sur des Ã©levages dâ€™animaux domestiques en France.&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="fr" dir="ltr">Avec des collÃ¨gues de &lt;a href="https://twitter.com/INRAE_France?ref_src=twsrc%5Etfw">@INRAE_France&lt;/a>, &lt;a href="https://twitter.com/Supagro?ref_src=twsrc%5Etfw">@Supagro&lt;/a>, &lt;a href="https://twitter.com/hashtag/CERPAM?src=hash&amp;amp;ref_src=twsrc%5Etfw">#CERPAM&lt;/a> et &lt;a href="https://twitter.com/OFBiodiversite?ref_src=twsrc%5Etfw">@OFBiodiversite&lt;/a>, nous proposons une analyse descriptive du phÃ©nomÃ¨ne de concentration dâ€™attaques de loup sur des Ã©levages dâ€™animaux domestiques en France &lt;a href="https://t.co/Ueyq5gkhi1">https://t.co/Ueyq5gkhi1&lt;/a> - &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> âž¡ï¸ &lt;a href="https://t.co/RKtvqjBVk0">https://t.co/RKtvqjBVk0&lt;/a> &lt;a href="https://t.co/qoup5jKauv">pic.twitter.com/qoup5jKauv&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez ðŸ–– (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1249341032661168128?ref_src=twsrc%5Etfw">April 12, 2020&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>MortalitÃ© en France et tidyverse</title><link>https://oliviergimenez.github.io/blog/procrastination_coulmont/</link><pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/procrastination_coulmont/</guid><description>&lt;blockquote class="twitter-tweet">&lt;p lang="fr" dir="ltr">Procrastination... Je me suis &amp;quot;amusÃ©&amp;quot; Ã  reproduire cette gÃ©niale figure de &lt;a href="https://twitter.com/coulmont?ref_src=twsrc%5Etfw">@coulmont&lt;/a> sur le jour des dÃ©cÃ¨s en ðŸ‡«ðŸ‡· en fonction de l&amp;#39;Ã¢ge et du temps avec &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> et le &lt;a href="https://twitter.com/hashtag/tidyverse?src=hash&amp;amp;ref_src=twsrc%5Etfw">#tidyverse&lt;/a> &lt;a href="https://t.co/W8QNBX5WlT">https://t.co/W8QNBX5WlT&lt;/a> &lt;a href="https://twitter.com/hashtag/ggplot2?src=hash&amp;amp;ref_src=twsrc%5Etfw">#ggplot2&lt;/a> &lt;a href="https://twitter.com/hashtag/dplyr?src=hash&amp;amp;ref_src=twsrc%5Etfw">#dplyr&lt;/a> &lt;a href="https://twitter.com/hashtag/lubridate?src=hash&amp;amp;ref_src=twsrc%5Etfw">#lubridate&lt;/a> &lt;a href="https://t.co/wOthJOBzBd">https://t.co/wOthJOBzBd&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez ðŸ–– (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1209172238009864193_src=twsrc%5Etfw">December 23, 2019&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Workshop on reproducible science</title><link>https://oliviergimenez.github.io/blog/cesabworkshop/</link><pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/cesabworkshop/</guid><description>&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">This week we host our first winter school on Â«Reproducible Research in Numerical Ecology Â» co-organised by &lt;a href="https://twitter.com/hashtag/GDR_Ecostat?src=hash&amp;amp;ref_src=twsrc%5Etfw">#GDR_Ecostat&lt;/a> &amp;amp; &lt;a href="https://twitter.com/hashtag/CESAB?src=hash&amp;amp;ref_src=twsrc%5Etfw">#CESAB&lt;/a> &lt;a href="https://twitter.com/FRBiodiv?ref_src=twsrc%5Etfw">@FRBiodiv&lt;/a>. Many thanks to our incredible list of speakers : Nicolas Casajus, StÃ©phane Dray, &lt;a href="https://twitter.com/GueryLorelei?ref_src=twsrc%5Etfw">@GueryLorelei&lt;/a>, &lt;a href="https://twitter.com/oaggimenez?ref_src=twsrc%5Etfw">@oaggimenez&lt;/a>, &lt;a href="https://twitter.com/FGuilhaumon?ref_src=twsrc%5Etfw">@FGuilhaumon&lt;/a> &amp;amp; &lt;a href="https://twitter.com/NinaSchiett?ref_src=twsrc%5Etfw">@NinaSchiett&lt;/a> !! &lt;a href="https://t.co/lRKlVXtYym">pic.twitter.com/lRKlVXtYym&lt;/a>&lt;/p>&amp;mdash; Nicolas Mouquet (@NicolasMouquet) &lt;a href="https://twitter.com/NicolasMouquet/status/1201490464945389568?ref_src=twsrc%5Etfw">December 2,2019&lt;/a>&lt;/blockquote> &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Introduction to spatial analyses in R</title><link>https://oliviergimenez.github.io/blog/intro_spatial/</link><pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/intro_spatial/</guid><description>&lt;blockquote class="twitter-tweet" data-lang="fr">&lt;p lang="en" dir="ltr">ðŸ‘©
ðŸ’»ðŸ—ºï¸ðŸ‘¨
ðŸ’» The slides of my introduction to &lt;a href="https://twitter.com/hashtag/GIS?src=hash&amp;amp;ref_src=twsrc%5Etfw">#GIS&lt;/a> and &lt;a href="https://twitter.com/hashtag/mapping?src=hash&amp;amp;ref_src=twsrc%5Etfw">#mapping&lt;/a> in &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> using the &lt;a href="https://twitter.com/hashtag/sf?src=hash&amp;amp;ref_src=twsrc%5Etfw">#sf&lt;/a> ðŸ“¦ and brown ðŸ» distribution in the &lt;a href="https://twitter.com/hashtag/pyrenees?src=hash&amp;amp;ref_src=twsrc%5Etfw">#pyrenees&lt;/a> as a case study &lt;a href="https://t.co/SKQOCzbxHn">https://t.co/SKQOCzbxHn&lt;/a> - raw material on &lt;a href="https://twitter.com/hashtag/github?src=hash&amp;amp;ref_src=twsrc%5Etfw">#github&lt;/a> &lt;a href="https://t.co/dHoMz6I2Kp">https://t.co/dHoMz6I2Kp&lt;/a> &lt;a href="https://twitter.com/hashtag/rspatial?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rspatial&lt;/a> &lt;a href="https://twitter.com/hashtag/spatial?src=hash&amp;amp;ref_src=twsrc%5Etfw">#spatial&lt;/a> &lt;a href="https://twitter.com/hashtag/ggplot2?src=hash&amp;amp;ref_src=twsrc%5Etfw">#ggplot2&lt;/a> &lt;a href="https://twitter.com/hashtag/tidyverse?src=hash&amp;amp;ref_src=twsrc%5Etfw">#tidyverse&lt;/a> &lt;a href="https://twitter.com/hashtag/dataviz?src=hash&amp;amp;ref_src=twsrc%5Etfw">#dataviz&lt;/a> &lt;a href="https://t.co/22eD1Y55d3">pic.twitter.com/22eD1Y55d3&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez ðŸ–– (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1093882504560414721?ref_src=twsrc%5Etfw">8 fÃ©vrier 2019&lt;/a>&lt;/blockquote>
&lt;script asyncc="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Introduction to the Tidyverse</title><link>https://oliviergimenez.github.io/blog/intro_tidyverse/</link><pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/intro_tidyverse/</guid><description>&lt;blockquote class="twitter-tweet" data-lang="fr">&lt;p lang="en" dir="ltr">My introduction to the &lt;a href="https://twitter.com/hashtag/tidyverse?src=hash&amp;amp;ref_src=twsrc%5Etfw">#tidyverse&lt;/a> for our lab meeting to manipulate and visualise data in &lt;a href="https://twitter.com/hashtag/rstat?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstat&lt;/a> &lt;a href="https://t.co/As9bkXY9GZ">https://t.co/As9bkXY9GZ&lt;/a>. Feel free to steal and modify this material for your own use. Be advised, this is work in progress &amp;amp; a mix of ðŸ‡¬ðŸ‡§/ðŸ‡«ðŸ‡·ðŸ˜‹ Comments welcome! &lt;a href="https://twitter.com/hashtag/datascience?src=hash&amp;amp;ref_src=twsrc%5Etfw">#datascience&lt;/a> &lt;a href="https://twitter.com/hashtag/davaviz?src=hash&amp;amp;ref_src=twsrc%5Etfw">#davaviz&lt;/a> &lt;a href="https://t.co/2vrrdbzuWh">pic.twitter.com/2vrrdbzuWh&lt;/a>&lt;/p>&amp;mdash; Olivier Gimenez ðŸ–– (@oaggimenez) &lt;a href="https://twitter.com/oaggimenez/status/1085492126404751360?ref_src=twsrc%5Etfw">16 janvier 2019&lt;/a>&lt;/blockote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script></description></item><item><title>Scientific research is all about networking</title><link>https://oliviergimenez.github.io/blog/network_ecology/</link><pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate><guid>https://oliviergimenez.github.io/blog/network_ecology/</guid><description>&lt;p>I read
&lt;a href="http://coulmont.com/blog/2018/12/02/sociologue-reseau-theses-2018/" target="_blank" rel="noopener">this awesome post&lt;/a> (in French) by
&lt;a href="http://coulmont.com/" target="_blank" rel="noopener">Baptiste Coulmont&lt;/a>, professor in sociology, who explored the French academic network in sociology. Coulmont used the composition of PhD commitees to determine academic links between colleagues. The approach very appealing because it uses public data available from the website
&lt;a href="www.these.fr">these.fr&lt;/a>. Here, I used Coulmont&amp;rsquo;s &lt;code>R&lt;/code> code to produce the French academic network in ecology. This was a nice opportunity to illustrate how to work in the &lt;code>tidyverse&lt;/code> and to do some
&lt;a href="https://en.wikipedia.org/wiki/Web_scraping" target="_blank" rel="noopener">web scraping&lt;/a> using the &lt;code>rvest&lt;/code> package.&lt;/p>
&lt;h2 id="get-the-data">Get the data&lt;/h2>
&lt;p>Load the packages we need:&lt;/p>
&lt;pre>&lt;code>library(RCurl)
library(tidyverse)
library(lubridate)
library(scales)
library(hrbrthemes)
library(data.table)
# devtools::install_github(&amp;quot;privefl/bigreadr&amp;quot;)
library(bigreadr)
&lt;/code>&lt;/pre>
&lt;p>We now prepare the URL requests. The total number of PhDs is around
88000 on the period 2015-2018. Because the website uses slices of 1000 on each page, we proceed
in sequence:&lt;/p>
&lt;pre>&lt;code>i &amp;lt;- 1:88
i &amp;lt;- i*1000
URL &amp;lt;-paste0(&amp;quot;http://www.theses.fr/?q=&amp;amp;fq=dateSoutenance:[2015-01-01T23:59:59Z%2BTO%2B2018-12-31T23:59:59Z]&amp;amp;checkedfacets=&amp;amp;start=&amp;quot;,i,&amp;quot;&amp;amp;sort=none&amp;amp;status=&amp;amp;access=&amp;amp;prevision=&amp;amp;filtrepersonne=&amp;amp;zone1=titreRAs&amp;amp;val1=&amp;amp;op1=AND&amp;amp;zone2=auteurs&amp;amp;val2=&amp;amp;op2=AND&amp;amp;zone3=etabSoutenances&amp;amp;val3=&amp;amp;zone4=dateSoutenance&amp;amp;val4a=&amp;amp;val4b=&amp;amp;type=&amp;amp;lng=&amp;amp;checkedfacets=&amp;amp;format=csv&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Alternatively, the search can be done by hand directly from the
&lt;a href="www.theses.fr">theses.fr&lt;/a> website. [FranÃ§ois-Xavier Coudert]
(&lt;a href="https://www.coudert.name/">https://www.coudert.name/&lt;/a>) also provides
&lt;a href="https://twitter.com/fxcoudert/status/1069188451898138624" target="_blank" rel="noopener">the search results for the
2015-2018
period&lt;/a>.&lt;/p>
&lt;p>We proceed with the requests, and store everything in a csv file:&lt;/p>
&lt;pre>&lt;code>j &amp;lt;- 1
SERP &amp;lt;- 1
for(j in 1:length(URL)){ # loop over the slices
SERP[j] &amp;lt;- getURL(URL[j])
write.csv(SERP,&amp;quot;SERP_2.csv&amp;quot;,append=F)
}
rm(SERP,i,j,URL)
&lt;/code>&lt;/pre>
&lt;p>We keep only the PhDs in the field (Discipline) of ecology. This is basically the only change I have made to Coulmont&amp;rsquo;s neat code.&lt;/p>
&lt;pre>&lt;code>theses &amp;lt;- read.csv(&amp;quot;SERP_2.csv&amp;quot;,sep=&amp;quot;;&amp;quot;,quote=&amp;quot;&amp;quot;,skip=1,stringsAsFactors = F)
#theses %&amp;gt;%
# pull(X..Discipline..) %&amp;gt;%
# unique()
ecology &amp;lt;- theses %&amp;gt;% filter(grepl(&amp;quot;ecologie&amp;quot;,X..Discipline..,ignore.case=T)) %&amp;gt;% # keep PhDs with Displine == ecologie
filter(X..Date.de.soutenance..!=&amp;quot;&amp;quot;) %&amp;gt;% # remove PhDs with missing dates of defense
filter(X..Statut..==&amp;quot;soutenue&amp;quot;) # keep only PhDs that have been defended
&lt;/code>&lt;/pre>
&lt;p>We now have the id of all PhDs in ecology defended during the period 2015-2018. We
will use the id to get the composition of all PhD commitees. Getting this composition
requires scraping the web page of each PhD, and to get the
ID of each PhD. For doing so, we use the &lt;code>rvest&lt;/code> package (see the
&lt;a href="https://masalmon.eu/tags/rvest/" target="_blank" rel="noopener">excellent posts&lt;/a>
by MaÃ«lle Salmon for examples).&lt;/p>
&lt;pre>&lt;code>library(rvest)
identifiants &amp;lt;- ecology$X..Identifiant.de.la.these.. # get PhD ids
reseau_total &amp;lt;- data_frame(noms_jury=&amp;quot;&amp;quot;,
liens_jury=&amp;quot;&amp;quot;,
these=&amp;quot;&amp;quot;,
directeurs=&amp;quot;&amp;quot;,
liens_directeurs=&amp;quot;&amp;quot;)
for (i in 1:length(identifiants)) {
# get info on current PhD
data_theses_eco &amp;lt;- read_html( paste0(&amp;quot;http://www.theses.fr/&amp;quot;,identifiants[i]) )
# get name PhD supervisor for
directeurs &amp;lt;- bind_cols(
directeurs = data_theses_eco %&amp;gt;%
html_nodes(&amp;quot;div .donnees-ombre p&amp;quot;) %&amp;gt;%
.[[1]] %&amp;gt;%
html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;%
html_text()
,
liens_directeurs = data_theses_eco %&amp;gt;%
html_nodes(&amp;quot;div .donnees-ombre p&amp;quot;) %&amp;gt;%
.[[1]] %&amp;gt;%
html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;%
html_attr(name=&amp;quot;href&amp;quot;)
) %&amp;gt;% mutate( these = identifiants[i] )
# get names of people in commitees
jury &amp;lt;- bind_cols(
noms_jury = data_theses_eco %&amp;gt;%
html_nodes(&amp;quot;div .donnees p a&amp;quot;) %&amp;gt;%
html_text()
,
liens_jury = data_theses_eco %&amp;gt;%
html_nodes(&amp;quot;div .donnees p a&amp;quot;) %&amp;gt;%
html_attr(name=&amp;quot;href&amp;quot;)
) %&amp;gt;% mutate( these = identifiants[i] )
# put all together
reseau &amp;lt;- jury %&amp;gt;% left_join(directeurs,by=&amp;quot;these&amp;quot;)
reseau_total &amp;lt;- bind_rows(reseau_total,reseau)
}
&lt;/code>&lt;/pre>
&lt;h2 id="build-the-network">Build the network&lt;/h2>
&lt;p>Load the packages we need, and the data we got at the previous step:&lt;/p>
&lt;pre>&lt;code>library(igraph)
library(ggraph)
library(ggrepel)
load('reseau_total.RData')
&lt;/code>&lt;/pre>
&lt;p>Coulmont defined a weighted link between two colleagues &lt;em>i&lt;/em> and &lt;em>j&lt;/em> as
follows: 3 if &lt;em>i&lt;/em> and &lt;em>j&lt;/em> are both supervisors, 2 if &lt;em>i&lt;/em> is a supervisor
and &lt;em>j&lt;/em> a PhD commitee member and 1 if both &lt;em>i&lt;/em> and &lt;em>j&lt;/em> are PhD commitee
members. A colleague may accumulate several weights.&lt;/p>
&lt;pre>&lt;code>directions_theses &amp;lt;- reseau_total %&amp;gt;%
select(these,directeurs) %&amp;gt;%
unique() %&amp;gt;%
group_by(these) %&amp;gt;%
mutate(N=n()) %&amp;gt;%
filter(N==2) %&amp;gt;% # keep co-supervision w/ 2 supervisors
mutate(rang=rank(directeurs)) %&amp;gt;%
spread(key=rang,value=directeurs) %&amp;gt;%
ungroup() %&amp;gt;%
select(nom1=`1`,nom2=`2`) %&amp;gt;%
mutate(poids=3)
directions_jury &amp;lt;- reseau_total %&amp;gt;%
select(nom1=noms_jury,nom2=directeurs) %&amp;gt;%
filter( nom1 != &amp;quot;&amp;quot;) %&amp;gt;%
mutate(poids=2) %&amp;gt;%
group_by(nom1,nom2) %&amp;gt;%
summarize(poids=sum(poids))
jury_jury &amp;lt;- reseau_total %&amp;gt;%
select(noms_jury,these) %&amp;gt;%
unique() %&amp;gt;%
filter(noms_jury!=&amp;quot;&amp;quot;)
g_j &amp;lt;- graph_from_data_frame(jury_jury,directed=F)
V(g_j)$type &amp;lt;- V(g_j)$name %in% jury_jury$noms_jury
g_j_1 &amp;lt;- bipartite_projection(g_j,which=&amp;quot;true&amp;quot;)
jurys &amp;lt;- as_long_data_frame(g_j_1) %&amp;gt;%
select(nom1=`ver[el[, 1], ]`, nom2=`ver2[el[, 2], ]`, poids=weight)
reseau_petit &amp;lt;- bind_rows(directions_theses,directions_jury,jurys) %&amp;gt;%
group_by(nom1,nom2) %&amp;gt;%
summarize(poids=sum(poids)) # data.frame from which the network will be created
&lt;/code>&lt;/pre>
&lt;p>Each node in the network has a size proportional to its
&lt;a href="https://en.wikipedia.org/wiki/Betweenness_centrality" target="_blank" rel="noopener">betweenness&lt;/a>
score. We also determine communities using the
&lt;a href="http://arxiv.org/abs/physics/0512106" target="_blank" rel="noopener">walktrap
algorithm&lt;/a> that will be colored differently. The width of an edge is
proportional to the strength of the link between the two corresponding
nodes.&lt;/p>
&lt;pre>&lt;code>g &amp;lt;- graph_from_data_frame(reseau_petit, directed=F) # create network from data.frame
g &amp;lt;- simplify(g,edge.attr.comb = sum)
V(g)$degres &amp;lt;- degree(g)
V(g)$label &amp;lt;- gsub(&amp;quot;^\\S+\\s+(.+)$&amp;quot;,&amp;quot;\\1&amp;quot;,V(g)$name)
V(g)$communaute &amp;lt;- as.character(cluster_walktrap(g, steps=15)$membership) # determine communities
V(g)$closeness &amp;lt;- (5*closeness(g))^10
V(g)$btwns &amp;lt;- betweenness(g) # network metric betweeness
V(g)$eigen_centr &amp;lt;- eigen_centrality(g)$vector
g &amp;lt;- delete_edges(g, which(E(g)$poids&amp;lt;5) ) # delete edges with weight &amp;lt;= 4
V(g)$cluster_number &amp;lt;- clusters(g)$membership # to which community you belong
g &amp;lt;- induced_subgraph(g, V(g)$cluster_number== which( max(clusters(g)$csize) == clusters(g)$csize) )
E(g)$weight &amp;lt;- 1/E(g)$poids # width of edge proportional to weight
V(g)$label &amp;lt;- ifelse(V(g)$degres&amp;lt;20,&amp;quot;&amp;quot;,V(g)$label) # do not display all names
&lt;/code>&lt;/pre>
&lt;h2 id="plot-the-network">Plot the network&lt;/h2>
&lt;p>We now plot the network. For clarity, we only indicate the names of
colleagues who were part of several phD commitees.&lt;/p>
&lt;pre>&lt;code>ggraph(g,layout=&amp;quot;igraph&amp;quot;,algorithm=&amp;quot;fr&amp;quot;) +
geom_edge_link(aes(width=.1*poids), alpha=.1,
end_cap = circle(5, 'mm'),
start_cap = circle(5, 'mm')) +
geom_node_point(aes(size=eigen_centr), color=&amp;quot;white&amp;quot;,alpha=1) +
geom_node_point(aes(color=communaute,size=eigen_centr), alpha=.5) +
scale_size_area(max_size = 20) +
geom_node_text(aes(label=label),size=3,repel=T,box.padding = 0.15) +
labs(title=&amp;quot;RÃ©seaux des Ã©cologues&amp;quot;,
subtitle=&amp;quot;Soutenances de thÃ¨ses entre 2015 et 2018&amp;quot;,
caption=&amp;quot;Sources : theses.fr \n Code par B. Coulmont, modifiÃ© par O. Gimenez&amp;quot;) +
theme_graph(foreground = 'white', fg_text_colour = 'white',
base_family = &amp;quot;Helvetica&amp;quot;) +
theme(legend.position=&amp;quot;none&amp;quot;,
text=element_text(size=16,family=&amp;quot;Helvetica&amp;quot;),
plot.margin = unit(c(0.2, 0.2, 0.2, 0.2), units=&amp;quot;line&amp;quot;))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://oliviergimenez.github.io/img/ecolnetwork.png" alt="">&lt;!-- -->&lt;/p>
&lt;pre>&lt;code># save
ggsave(filename = &amp;quot;ecology_network.pdf&amp;quot;,width=30,height = 20)
&lt;/code>&lt;/pre>
&lt;p>I played around the defaults Coulmont used to build and plot the network. It helps in getting a better understanding of the network and the links between colleagues working in ecology. Overall, I indeed feel very much connected to my colleagues in Montpellier, Lyon and Grenoble. I should probably go out of my comfort zone and interact even more with my colleagues from La Rochelle, Marseille and Aix-en-Provence ðŸ˜ƒ&lt;/p>
&lt;p>As always, data and code are available from
&lt;a href="https://github.com/oliviergimenez/phd-in-ecology-network/" target="_blank" rel="noopener">GitHub&lt;/a>.&lt;/p></description></item></channel></rss>