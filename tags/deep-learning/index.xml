<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>deep-learning | Olivier Gimenez</title>
    <link>https://oliviergimenez.github.io/tags/deep-learning/</link>
      <atom:link href="https://oliviergimenez.github.io/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>deep-learning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>¬© Olivier Gimenez 2023</copyright><lastBuildDate>Mon, 22 May 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://oliviergimenez.github.io/img/flyfishing.jpg</url>
      <title>deep-learning</title>
      <link>https://oliviergimenez.github.io/tags/deep-learning/</link>
    </image>
    
    <item>
      <title>Nine tips for ecologists using machine learning</title>
      <link>https://oliviergimenez.github.io/blog/preprintml/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      <guid>https://oliviergimenez.github.io/blog/preprintml/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;New preprint led by Marine Desprez w/ Vincent Miele on &amp;quot;Nine tips for ecologists using machine learning&amp;quot; ü§©&lt;a href=&#34;https://twitter.com/hashtag/MachineLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#MachineLearning&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Ecology?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Ecology&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/RStats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#RStats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/preprint?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#preprint&lt;/a&gt;&lt;a href=&#34;https://t.co/KvXTmhABtF&#34;&gt;https://t.co/KvXTmhABtF&lt;/a&gt;&lt;a href=&#34;https://twitter.com/LbbeLyon?ref_src=twsrc%5Etfw&#34;&gt;@LbbeLyon&lt;/a&gt; &lt;a href=&#34;https://twitter.com/cefemontpellier?ref_src=twsrc%5Etfw&#34;&gt;@cefemontpellier&lt;/a&gt; &lt;a href=&#34;https://twitter.com/INEE_CNRS?ref_src=twsrc%5Etfw&#34;&gt;@INEE_CNRS&lt;/a&gt; &lt;a href=&#34;https://twitter.com/CNRS_OccitaniE?ref_src=twsrc%5Etfw&#34;&gt;@CNRS_OccitaniE&lt;/a&gt; &lt;a href=&#34;https://twitter.com/umontpellier?ref_src=twsrc%5Etfw&#34;&gt;@umontpellier&lt;/a&gt; &lt;a href=&#34;https://t.co/CbiFOIjXhX&#34;&gt;pic.twitter.com/CbiFOIjXhX&lt;/a&gt;&lt;/p&gt;&amp;mdash; Olivier Gimenez üññü¶¶ (@oaggimenez) &lt;a href=&#34;https://twitter.com/oaggimenez/status/1660576083538788353?ref_src=twsrc%5Etfw&#34;&gt;May 22, 2023&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt; </description>
    </item>
    
    <item>
      <title>New paper on trade-offs between Deep Learning for species id inference on predator-prey co-occurrence</title>
      <link>https://oliviergimenez.github.io/blog/2022-04-06-new-paper-on-trade-offs-between-deep-learning-for-species-id-inference-on-predator-prey-co-occurrence/</link>
      <pubDate>Wed, 06 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://oliviergimenez.github.io/blog/2022-04-06-new-paper-on-trade-offs-between-deep-learning-for-species-id-inference-on-predator-prey-co-occurrence/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;A pleasure to work w/ &lt;a href=&#34;https://twitter.com/hashtag/ComputoJournal?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ComputoJournal&lt;/a&gt; &lt;a href=&#34;https://twitter.com/Computo85445972?ref_src=twsrc%5Etfw&#34;&gt;@Computo85445972&lt;/a&gt; for our paper on trade-offs bw &lt;a href=&#34;https://twitter.com/hashtag/DeepLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DeepLearning&lt;/a&gt; for species id &amp;amp; inference on predator-prey co-occurrence, which comes w/ a reproducible R workflow üòá&lt;a href=&#34;https://t.co/Tgo6OJs7r0&#34;&gt;https://t.co/Tgo6OJs7r0&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/OpenAccess?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#OpenAccess&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/ReproducibleResearch?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#ReproducibleResearch&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/RStats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#RStats&lt;/a&gt; &lt;br&gt;&lt;br&gt; üßµ‚¨áÔ∏è &lt;a href=&#34;https://t.co/x2w73ezAcs&#34;&gt;https://t.co/x2w73ezAcs&lt;/a&gt;&lt;/p&gt;&amp;mdash; Olivier Gimenez üññ (@oaggimenez) &lt;a href=&#34;https://twitter.com/oaggimenez/status/1511699911238111236?ref_src=twsrc%5Etfw&#34;&gt;April 6, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt; 
</description>
    </item>
    
    <item>
      <title>Binary image classification using Keras in R: Using CT scans to predict patients with Covid</title>
      <link>https://oliviergimenez.github.io/blog/image-classif/</link>
      <pubDate>Sun, 02 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://oliviergimenez.github.io/blog/image-classif/</guid>
      <description>&lt;p&gt;Here I illustrate how to train a CNN with Keras in R to predict from patients&amp;rsquo; CT scans those who will develop severe illness from Covid.&lt;/p&gt;
&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;
&lt;p&gt;Michael Blum 
&lt;a href=&#34;https://twitter.com/mblum_g/status/1475940763716444161?s=20&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tweeted&lt;/a&gt; about the 
&lt;a href=&#34;https://stoic2021.grand-challenge.org/stoic2021/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;STOIC2021 - COVID-19 AI challenge&lt;/a&gt;. The main goal of this challenge is to predict from the patients&amp;rsquo; 
&lt;a href=&#34;https://en.wikipedia.org/wiki/CT_scan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CT scans&lt;/a&gt; who will develop severe illness from Covid.&lt;/p&gt;
&lt;p&gt;Given my 
&lt;a href=&#34;https://oliviergimenez.github.io/blog/learning-machine-learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;recent interest in machine learning&lt;/a&gt;, this challenge peaked my interest. Although &lt;code&gt;Python&lt;/code&gt; is the machine learning &lt;em&gt;lingua franca&lt;/em&gt;, it is possible to 
&lt;a href=&#34;https://github.com/oliviergimenez/computo-deeplearning-occupany-lynx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;train a convolutional neural network (CNN) in &lt;code&gt;R&lt;/code&gt;&lt;/a&gt; and perform (binary) image classification.&lt;/p&gt;
&lt;p&gt;Here, I will use an 
&lt;a href=&#34;https://keras.rstudio.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;R&lt;/code&gt; interface to &lt;code&gt;Keras&lt;/code&gt;&lt;/a&gt; that allows training neural networks. Note that the 
&lt;a href=&#34;https://stoic2021.grand-challenge.org/stoic-db/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;dataset shared for the challenge&lt;/a&gt; is big, like 280Go big, and it took me a day to download it. For the sake of illustration, I will use a similar but much lighter dataset from a 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Kaggle&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kaggle&lt;/a&gt; repository 
&lt;a href=&#34;https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The code is available on GitHub as usual 
&lt;a href=&#34;https://github.com/oliviergimenez/bin-image-classif&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/oliviergimenez/bin-image-classif&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First things first, load the packages we will need.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
theme_set(theme_light())
library(keras)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;read-in-and-process-data&#34;&gt;Read in and process data&lt;/h1&gt;
&lt;p&gt;We will need a function to process images, I&amp;rsquo;m stealing 
&lt;a href=&#34;https://rpubs.com/spalladino14/653239&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;that one&lt;/a&gt; written by 
&lt;a href=&#34;https://www.linkedin.com/in/spencer-palladino/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Spencer Palladino&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;process_pix &amp;lt;- function(lsf) {
  img &amp;lt;- lapply(lsf, image_load, grayscale = TRUE) # grayscale the image
  arr &amp;lt;- lapply(img, image_to_array) # turns it into an array
  arr_resized &amp;lt;- lapply(arr, image_array_resize, 
                        height = 100, 
                        width = 100) # resize
  arr_normalized &amp;lt;- normalize(arr_resized, axis = 1) #normalize to make small numbers 
  return(arr_normalized)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s process images for patients with Covid, and do some reshaping. Idem with images for patients without Covid.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# with covid
lsf &amp;lt;- list.files(&amp;quot;dat/COVID/&amp;quot;, full.names = TRUE) 
covid &amp;lt;- process_pix(lsf)
covid &amp;lt;- covid[,,,1] # get rid of last dim
covid_reshaped &amp;lt;- array_reshape(covid, c(nrow(covid), 100*100))
# without covid
lsf &amp;lt;- list.files(&amp;quot;dat/non-COVID/&amp;quot;, full.names = TRUE) 
ncovid &amp;lt;- process_pix(lsf)
ncovid &amp;lt;- ncovid[,,,1] # get rid of last dim
ncovid_reshaped &amp;lt;- array_reshape(ncovid, c(nrow(ncovid), 100*100))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have 1252 CT scans of patients with Covid, and 1229 without.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s visualise these scans. Let&amp;rsquo;s pick a patient with Covid, and another one without.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;scancovid &amp;lt;- reshape2::melt(covid[10,,])
plotcovid &amp;lt;- scancovid %&amp;gt;%
  ggplot() +
  aes(x = Var1, y = Var2, fill = value) + 
  geom_raster() +
  labs(x = NULL, y = NULL, title = &amp;quot;CT scan of a patient with covid&amp;quot;) + 
  scale_fill_viridis_c() + 
  theme(legend.position = &amp;quot;none&amp;quot;)

scanncovid &amp;lt;- reshape2::melt(ncovid[10,,])
plotncovid &amp;lt;- scanncovid %&amp;gt;%
  ggplot() +
  aes(x = Var1, y = Var2, fill = value) + 
  geom_raster() +
  labs(x = NULL, y = NULL, title = &amp;quot;CT scan of a patient without covid&amp;quot;) + 
  scale_fill_viridis_c() + 
  theme(legend.position = &amp;quot;none&amp;quot;)

library(patchwork)
plotcovid + plotncovid
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;unnamed-chunk-4-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Put altogether and shuffle.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df &amp;lt;- rbind(cbind(covid_reshaped, 1), # 1 = covid
            cbind(ncovid_reshaped, 0)) # 0 = no covid
set.seed(1234)
shuffle &amp;lt;- sample(nrow(df), replace = F)
df &amp;lt;- df[shuffle, ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sounds great. We have everything we need to start training a convolutional neural network model.&lt;/p&gt;
&lt;h1 id=&#34;convolutional-neural-network-cnn&#34;&gt;Convolutional neural network (CNN)&lt;/h1&gt;
&lt;p&gt;Let&amp;rsquo;s build our training and testing datasets using a 80/20 split.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(2022)
split &amp;lt;- sample(2, nrow(df), replace = T, prob = c(0.8, 0.2))
train &amp;lt;- df[split == 1,]
test &amp;lt;- df[split == 2,]
train_target &amp;lt;- df[split == 1, 10001] # label in training dataset
test_target &amp;lt;- df[split == 2, 10001] # label in testing dataset
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now build our model. I use three layers (&lt;code&gt;layer_dense()&lt;/code&gt; function) that I put one after the other with piping. I also use regularization (&lt;code&gt;layer_dropout()&lt;/code&gt; function) to avoid overfitting.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model &amp;lt;- keras_model_sequential() %&amp;gt;%
  layer_dense(units = 512, activation = &amp;quot;relu&amp;quot;) %&amp;gt;% 
  layer_dropout(0.4) %&amp;gt;%
  layer_dense(units = 256, activation = &amp;quot;relu&amp;quot;) %&amp;gt;%
  layer_dropout(0.3) %&amp;gt;%
  layer_dense(units = 128, activation = &amp;quot;relu&amp;quot;) %&amp;gt;%
  layer_dropout(0.2) %&amp;gt;%
  layer_dense(units = 2, activation = &#39;softmax&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compile the model with defaults specific to binary classification.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model %&amp;gt;%
  compile(optimizer = &#39;adam&#39;,
          loss = &#39;binary_crossentropy&#39;, 
          metrics = c(&#39;accuracy&#39;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We use one-hot encoding (&lt;code&gt;to_categorical()&lt;/code&gt; function) aka dummy coding in statistics.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train_label &amp;lt;- to_categorical(train_target)
test_label &amp;lt;- to_categorical(test_target)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let&amp;rsquo;s fit our model to the training dataset.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fit_covid &amp;lt;- model %&amp;gt;%
  fit(x = train,
      y = train_label, 
      epochs = 25,
      batch_size = 512, # try also 128 and 256
      verbose = 2,
      validation_split = 0.2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A quick visualization of the performances shows that the algorithm is doing not too bad. No over/under-fitting. Accuracy and loss are fine.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(fit_covid)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;unnamed-chunk-11-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;What about the performances on the testing dataset?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model %&amp;gt;%
  evaluate(test, test_label)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       loss   accuracy 
## 0.02048795 0.99795920
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s do some predictions on the testing dataset, and compare with ground truth.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;predictedclasses &amp;lt;- model %&amp;gt;%
  predict_classes(test)
table(Prediction = predictedclasses, 
      Actual = test_target)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Actual
## Prediction   0   1
##          0 243   0
##          1   1 246
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pretty cool. Only one healthy patient is misclassified as being sick. Let&amp;rsquo;s save our model for further use.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;save_model_tf(model, &amp;quot;model/covidmodel&amp;quot;) # save the model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I&amp;rsquo;m happy with these results. In general however, we need to find ways to improve the performances. Check out some tips 
&lt;a href=&#34;https://machinelearningmastery.com/improve-deep-learning-performance/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; with examples implemented in &lt;code&gt;Keras&lt;/code&gt; with &lt;code&gt;R&lt;/code&gt; 
&lt;a href=&#34;https://keras.rstudio.com/articles/examples/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;there&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Regard SFEE Images, √©cologie et deep learning</title>
      <link>https://oliviergimenez.github.io/blog/sfeeia/</link>
      <pubDate>Mon, 22 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://oliviergimenez.github.io/blog/sfeeia/</guid>
      <description>&lt;p&gt;Our take on deep learning, computer vision and ecology.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;fr&#34; dir=&#34;ltr&#34;&gt;&amp;quot;Images, √©cologie et deep learning&amp;quot; co-√©crit avec Vincent Miele et St√©phane Dray &lt;a href=&#34;https://twitter.com/LbbeLyon?ref_src=twsrc%5Etfw&#34;&gt;@LbbeLyon&lt;/a&gt; sur les applications du &lt;a href=&#34;https://twitter.com/hashtag/DeepLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DeepLearning&lt;/a&gt; √† l&amp;#39;analyse d&amp;#39;images en √©cologie et difficult√©s associ√©es. üôè &lt;a href=&#34;https://twitter.com/sfecologie?ref_src=twsrc%5Etfw&#34;&gt;@sfecologie&lt;/a&gt; pour l&amp;#39;opportunit√© &lt;a href=&#34;https://t.co/0cTYbHTb35&#34;&gt;https://t.co/0cTYbHTb35&lt;/a&gt; &lt;a href=&#34;https://twitter.com/INEE_CNRS?ref_src=twsrc%5Etfw&#34;&gt;@INEE_CNRS&lt;/a&gt; &lt;a href=&#34;https://twitter.com/cefemontpellier?ref_src=twsrc%5Etfw&#34;&gt;@cefemontpellier&lt;/a&gt;&lt;/p&gt;&amp;mdash; Olivier Gimenez üññ (@oaggimenez) &lt;a href=&#34;https://twitter.com/oaggimenez/status/1363971047675072516?ref_src=twsrc%5Etfw&#34;&gt;February 22, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;</description>
    </item>
    
    <item>
      <title>Workshop on Deep Learning and Ecology</title>
      <link>https://oliviergimenez.github.io/blog/deeplearning/</link>
      <pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://oliviergimenez.github.io/blog/deeplearning/</guid>
      <description>&lt;p&gt;Co-organised a workshop on deep learning applications in ecology. Thread below and my notes 
&lt;a href=&#34;https://twitter.com/oaggimenez/status/1329091540082257924?s=20&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;there&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;ü•Åü§© Our workshop on &lt;a href=&#34;https://twitter.com/hashtag/DeepLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DeepLearning&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/hashtag/Ecology?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Ecology&lt;/a&gt; is about to begin. We&amp;#39;ll be talking about how to process and analyse images üì∏ and sounds üéôÔ∏è &lt;br&gt;&lt;br&gt;Program: &lt;a href=&#34;https://t.co/gUXD0tMCW1&#34;&gt;https://t.co/gUXD0tMCW1&lt;/a&gt;&lt;br&gt;Curated list of resources for ecologists: &lt;a href=&#34;https://t.co/HieQfqgVEx&#34;&gt;https://t.co/HieQfqgVEx&lt;/a&gt; &lt;br&gt;GDR EcoStat: &lt;a href=&#34;https://t.co/kTXpjJXlya&#34;&gt;https://t.co/kTXpjJXlya&lt;/a&gt; &lt;a href=&#34;https://t.co/nfjVke9ETU&#34;&gt;pic.twitter.com/nfjVke9ETU&lt;/a&gt;&lt;/p&gt;&amp;mdash; Olivier Gimenez üññ (@oaggimenez) &lt;a href=&#34;https://twitter.com/oaggimenez/status/1328238117049012224?ref_src=twsrc%5Etfw&#34;&gt;November 16, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;</description>
    </item>
    
    <item>
      <title>Tagging species with deep learning.</title>
      <link>https://oliviergimenez.github.io/blog/dlcameras/</link>
      <pubDate>Mon, 11 May 2020 00:00:00 +0000</pubDate>
      <guid>https://oliviergimenez.github.io/blog/dlcameras/</guid>
      <description>&lt;p&gt;Tagging species with deep learning.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Tagging species w/ &lt;a href=&#34;https://twitter.com/hashtag/Keras?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Keras&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Retinanet?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Retinanet&lt;/a&gt; &lt;a href=&#34;https://t.co/lZRlrDHtfM&#34;&gt;https://t.co/lZRlrDHtfM&lt;/a&gt; &lt;a href=&#34;https://twitter.com/FizyrBV?ref_src=twsrc%5Etfw&#34;&gt;@FizyrBV&lt;/a&gt; Not too bad so far ü§© green box is truth, blue/orange box is prediction &lt;a href=&#34;https://twitter.com/hashtag/DeepLearning?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DeepLearning&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/CameraTraps?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CameraTraps&lt;/a&gt; More details ‚û°Ô∏è &lt;a href=&#34;https://t.co/HieQfqgVEx&#34;&gt;https://t.co/HieQfqgVEx&lt;/a&gt; &lt;a href=&#34;https://t.co/uhocKDuuGP&#34;&gt;pic.twitter.com/uhocKDuuGP&lt;/a&gt;&lt;/p&gt;&amp;mdash; Olivier Gimenez üññ (@oaggimenez) &lt;a href=&#34;https://twitter.com/oaggimenez/status/1259869148584214528?ref_src=twsrc%5Etfw&#34;&gt;May 11, 220&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;</description>
    </item>
    
  </channel>
</rss>
